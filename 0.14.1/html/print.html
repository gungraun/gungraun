<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Iai-Callgrind Guide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="Iai-Callgrind, a high-precision and consistent one-shot benchmarking framework/harness for Rust">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="css/my.css">
        <link rel="stylesheet" href="css/dropdown.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="getting_help.html"><strong aria-hidden="true">2.</strong> Getting Help</a></li><li class="chapter-item expanded affix "><li class="part-title">Installation</li><li class="chapter-item expanded "><a href="installation/prerequisites.html"><strong aria-hidden="true">3.</strong> Prerequisites</a></li><li class="chapter-item expanded "><a href="installation/iai_callgrind.html"><strong aria-hidden="true">4.</strong> Iai-Callgrind</a></li><li class="chapter-item expanded affix "><li class="part-title">Benchmarks</li><li class="chapter-item expanded "><a href="benchmarks/overview.html"><strong aria-hidden="true">5.</strong> Overview</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks.html"><strong aria-hidden="true">6.</strong> Library Benchmarks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/important.html"><strong aria-hidden="true">6.1.</strong> Important default behaviour</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/quickstart.html"><strong aria-hidden="true">6.2.</strong> Quickstart</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/anatomy.html"><strong aria-hidden="true">6.3.</strong> Anatomy of a library benchmark</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/macros.html"><strong aria-hidden="true">6.4.</strong> The macros in more detail</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/setup_and_teardown.html"><strong aria-hidden="true">6.5.</strong> setup and teardown</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/multiple_benches.html"><strong aria-hidden="true">6.6.</strong> Specify multiple benches at once</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/generic.html"><strong aria-hidden="true">6.7.</strong> Generic benchmark functions</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/compare_by_id.html"><strong aria-hidden="true">6.8.</strong> Comparing benchmark functions</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/configuration.html"><strong aria-hidden="true">6.9.</strong> Configuration</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/custom_entry_point.html"><strong aria-hidden="true">6.10.</strong> Custom entry points</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/threads_and_subprocesses.html"><strong aria-hidden="true">6.11.</strong> Multi-threaded and multi-process applications</a></li><li class="chapter-item expanded "><a href="benchmarks/library_benchmarks/examples.html"><strong aria-hidden="true">6.12.</strong> More Examples, please!</a></li></ol></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks.html"><strong aria-hidden="true">7.</strong> Binary Benchmarks</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/important.html"><strong aria-hidden="true">7.1.</strong> Important default behaviour</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/quickstart.html"><strong aria-hidden="true">7.2.</strong> Quickstart</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/differences.html"><strong aria-hidden="true">7.3.</strong> Differences to library benchmarks</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/stdin_and_pipe.html"><strong aria-hidden="true">7.4.</strong> The Command's stdin and simulating piped input</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/configuration.html"><strong aria-hidden="true">7.5.</strong> Configuration</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/configuration/delay.html"><strong aria-hidden="true">7.5.1.</strong> Delay the Command</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/configuration/sandbox.html"><strong aria-hidden="true">7.5.2.</strong> Sandbox</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/configuration/exit_code.html"><strong aria-hidden="true">7.5.3.</strong> Configure the exit code of the Command</a></li></ol></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/low_level.html"><strong aria-hidden="true">7.6.</strong> Low-level api</a></li><li class="chapter-item expanded "><a href="benchmarks/binary_benchmarks/examples.html"><strong aria-hidden="true">7.7.</strong> More examples needed?</a></li></ol></li><li class="chapter-item expanded "><a href="regressions.html"><strong aria-hidden="true">8.</strong> Performance Regressions</a></li><li class="chapter-item expanded "><a href="tools.html"><strong aria-hidden="true">9.</strong> Other Valgrind Tools</a></li><li class="chapter-item expanded "><a href="client_requests.html"><strong aria-hidden="true">10.</strong> Valgrind Client Requests</a></li><li class="chapter-item expanded "><a href="flamegraphs.html"><strong aria-hidden="true">11.</strong> Callgrind Flamegraphs</a></li><li class="chapter-item expanded affix "><li class="part-title">Command-line and environment variables</li><li class="chapter-item expanded "><a href="cli_and_env/basics.html"><strong aria-hidden="true">12.</strong> Basic usage</a></li><li class="chapter-item expanded "><a href="cli_and_env/baselines.html"><strong aria-hidden="true">13.</strong> Comparing with baselines</a></li><li class="chapter-item expanded "><a href="cli_and_env/output.html"><strong aria-hidden="true">14.</strong> Controlling the output of Iai-Callgrind</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="cli_and_env/output/out_directory.html"><strong aria-hidden="true">14.1.</strong> Customize the output directory</a></li><li class="chapter-item expanded "><a href="cli_and_env/output/machine_readable.html"><strong aria-hidden="true">14.2.</strong> Machine-readable output</a></li><li class="chapter-item expanded "><a href="cli_and_env/output/terminal_output.html"><strong aria-hidden="true">14.3.</strong> Showing terminal output of benchmarks</a></li><li class="chapter-item expanded "><a href="cli_and_env/output/color.html"><strong aria-hidden="true">14.4.</strong> Changing the color output</a></li><li class="chapter-item expanded "><a href="cli_and_env/output/logging.html"><strong aria-hidden="true">14.5.</strong> Changing the logging output</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Troubleshooting</li><li class="chapter-item expanded "><a href="troubleshooting/im-getting-the-error-sentinel-not-found.html"><strong aria-hidden="true">15.</strong> I'm getting the error Sentinel ... not found</a></li><li class="chapter-item expanded "><a href="troubleshooting/running-cargo-bench-results-in-an-unrecognized-option-error.html"><strong aria-hidden="true">16.</strong> Running cargo bench results in an "Unrecognized Option" error</a></li><li class="chapter-item expanded affix "><li class="part-title">Comparison</li><li class="chapter-item expanded "><a href="comparison/criterion.html"><strong aria-hidden="true">17.</strong> Criterion</a></li><li class="chapter-item expanded "><a href="comparison/iai.html"><strong aria-hidden="true">18.</strong> Iai</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        <div class="dropdown">
                          <button onclick="versionDropdown()" class="icon-button version-dropdown-button" type="button">Version</button>
                          <div id="version-dropdown" class="version-dropdown-content">
                            <a href="../../latest/html/index.html">Latest</a>
                            <hr class="sidbar-spacer">
                            <script src="../../versions.js"></script>
                          </div>
                        </div>
                    </div>

                    <h1 class="menu-title">Iai-Callgrind Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/iai-callgrind/iai-callgrind" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>This is the guide for Iai-Callgrind, a benchmarking framework/harness which uses
<a href="https://valgrind.org/docs/manual/cl-manual.html">Valgrind's Callgrind</a> and
other Valgrind tools like DHAT, Massif, ... to provide extremely accurate and
consistent measurements of Rust code, making it perfectly suited to run in
environments like a CI.</p>
<p>Iai_Callgrind is fully documented in this guide and in the api documentation at
<a href="https://docs.rs/iai-callgrind/latest/iai_callgrind/">docs.rs</a>.</p>
<p>Iai-Callgrind is</p>
<ul>
<li><strong>Precise</strong>: High-precision measurements of <code>Instruction</code> counts and many
other metrics allow you to reliably detect very small optimizations and
regressions of your code.</li>
<li><strong>Consistent</strong>: Iai-Callgrind can take accurate measurements even in
virtualized CI environments and make them comparable between different systems
completely negating the noise of the environment.</li>
<li><strong>Fast</strong>: Each benchmark is only run once, which is usually much faster than
benchmarks which measure execution and wall-clock time. Benchmarks measuring
the wall-clock time have to be run many times to increase their accuracy,
detect outliers, filter out noise, etc.</li>
<li><strong>Visualizable</strong>: Iai-Callgrind generates a Callgrind (DHAT, ...) profile of
the benchmarked code and can be configured to create flamegraph-like charts
from Callgrind metrics. In general, all Valgrind-compatible tools like
<a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.callgrind_annotate-options">callgrind_annotate</a>,
<a href="https://kcachegrind.github.io/html/Home.html">kcachegrind</a> or <code>dh_view.html</code>
and others to analyze the results in detail are fully supported.</li>
<li><strong>Easy</strong>: The API for setting up benchmarks is easy to use and allows you to
quickly create concise and clear benchmarks. Focus more on profiling and your
code than on the framework.</li>
</ul>
<h2 id="design-philosophy-and-goals"><a class="header" href="#design-philosophy-and-goals">Design philosophy and goals</a></h2>
<p>Iai-Callgrind benchmarks are designed to be runnable with <code>cargo bench</code>. The
benchmark files are expanded to a benchmarking harness which replaces the native
benchmark harness of <code>rust</code>. Iai-Callgrind is a profiling framework that can
quickly and reliably detect performance regressions and optimizations even in
noisy environments with a precision that is impossible to achieve with
wall-clock time based benchmarks. At the same time, we want to abstract the
complicated parts and repetitive tasks away and provide an easy to use and
intuitive api. Iai-Callgrind tries to stay out of your way so you can focus more
on profiling and your code!</p>
<h2 id="when-not-to-use-iai-callgrind"><a class="header" href="#when-not-to-use-iai-callgrind">When not to use Iai-Callgrind</a></h2>
<p>Although Iai-Callgrind is useful in many projects, there are cases where
Iai-Callgrind is not a good fit.</p>
<ul>
<li>If you need wall-clock times, Iai-Callgrind cannot help you much. The
estimation of cpu cycles merely correlates to wall-clock times but is not a
replacement for wall-clock times. The cycles estimation is primarily designed
to be a relative metric to be used for comparison.</li>
<li>Iai-Callgrind cannot be run on Windows and platforms not supported by
Valgrind.</li>
</ul>
<h2 id="improving-iai-callgrind"><a class="header" href="#improving-iai-callgrind">Improving Iai-Callgrind</a></h2>
<p>No one's perfect!</p>
<p>You want to share your experience with Iai-Callgrind and have a recipe that
might be useful for others and fits into this guide? You have an idea for a new
feature, are missing a functionality or have found a bug? We would love to here
about it. You want to contribute and hack on Iai-Callgrind?</p>
<p>Please don't hesitate to <a href="https://github.com/iai-callgrind/iai-callgrind/issues">open an
issue</a>.</p>
<p>You want to hack on this guide? The source code of this book lives in <a href="https://github.com/iai-callgrind/iai-callgrind/tree/main/docs">the docs
subdirectory</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h1>
<p>Reach out to us on <a href="https://github.com/iai-callgrind/iai-callgrind/discussions">Github
Discussions</a> or open
an <a href="https://github.com/iai-callgrind/iai-callgrind/issues">Issue</a> in the
<a href="https://github.com/iai-callgrind/iai-callgrind">Iai-Callgrind
Repository</a>. Check the
open and closed issues in the issue board, maybe you can already find a solution
to your problem there.</p>
<p>The api documentation can be found on
<a href="https://docs.rs/iai-callgrind/latest/iai_callgrind/">docs.rs</a> but you might
also want to check out the <code>Troubleshooting</code> section in the sidebar of this
guide.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h1>
<p>In order to use Iai-Callgrind, you must have <a href="https://www.valgrind.org">Valgrind</a> installed. This
means that Iai-Callgrind cannot be used on platforms that are not supported by Valgrind.</p>
<h2 id="debug-symbols"><a class="header" href="#debug-symbols">Debug Symbols</a></h2>
<p>It's required to run the Iai-Callgrind benchmarks with debugging symbols
switched on. For example in your <code>~/.cargo/config</code> or your project's
<code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[profile.bench]
debug = true
</code></pre>
<p>Now, all benchmarks which are run with <code>cargo bench</code> include the debug symbols.
(See also <a href="https://doc.rust-lang.org/cargo/reference/profiles.html">Cargo
Profiles</a> and <a href="https://doc.rust-lang.org/cargo/reference/config.html">Cargo
Config</a>).</p>
<p>It's required that settings like <code>strip = true</code> or other configuration options
stripping the debug symbols need to be disabled explicitly for the <code>bench</code>
profile if you have changed this option for the <code>release</code> profile. For example:</p>
<pre><code class="language-toml">[profile.release]
strip = true

[profile.bench]
debug = true
strip = false
</code></pre>
<h2 id="valgrind-client-requests"><a class="header" href="#valgrind-client-requests">Valgrind Client Requests</a></h2>
<p>If you want to make use of the mighty <a href="https://valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.clientreq">Valgrind Client Request
Mechanism</a>
shipped with Iai-Callgrind, you also need <code>libclang</code> (clang &gt;= 5.0) installed.
See also the requirements of
<a href="https://rust-lang.github.io/rust-bindgen/requirements.html">bindgen</a> and of
<a href="https://github.com/rust-lang/cc-rs">cc</a>.</p>
<p>More details on the usage and requirements of Valgrind Client Requests in
<a href="installation/../client_requests.html">this</a> chapter of the guide.</p>
<h2 id="installation-of-valgrind"><a class="header" href="#installation-of-valgrind">Installation of Valgrind</a></h2>
<p>Iai-Callgrind is intentionally independent of a specific version of valgrind.
However, Iai-Callgrind was only tested with versions of valgrind &gt;= <code>3.20.0</code>. It
is therefore highly recommended to use a recent version of valgrind. Bugs get
fixed, the supported platforms are expanded ... Also, if you want or need to,
<a href="https://sourceware.org/git/?p=valgrind.git;a=blob;f=README;h=eabcc6ad88c8cab6dfe73cfaaaf5543023c2e941;hb=HEAD">building valgrind from
source</a>
is usually a straight-forward process. Just make sure the <code>valgrind</code> binary is
in your <code>$PATH</code> so that Iai-callgrind can find it.</p>
<h3 id="installation-of-valgrind-with-your-package-manager"><a class="header" href="#installation-of-valgrind-with-your-package-manager">Installation of valgrind with your package manager</a></h3>
<h4 id="alpine-linux"><a class="header" href="#alpine-linux">Alpine Linux</a></h4>
<pre><code class="language-bash">apk add just
</code></pre>
<h4 id="arch-linux"><a class="header" href="#arch-linux">Arch Linux</a></h4>
<pre><code class="language-bash">pacman -Sy valgrind
</code></pre>
<h4 id="debianubuntu"><a class="header" href="#debianubuntu">Debian/Ubuntu</a></h4>
<pre><code class="language-bash">apt-get install valgrind
</code></pre>
<h4 id="fedora-linux"><a class="header" href="#fedora-linux">Fedora Linux</a></h4>
<pre><code class="language-bash">dnf install valgrind
</code></pre>
<h4 id="freebsd"><a class="header" href="#freebsd">FreeBSD</a></h4>
<pre><code class="language-bash">pkg install valgrind
</code></pre>
<h4 id="valgrind-is-available-for-the-following-distributions"><a class="header" href="#valgrind-is-available-for-the-following-distributions">Valgrind is available for the following distributions</a></h4>
<p><a href="https://repology.org/project/valgrind/versions"><img src="https://repology.org/badge/vertical-allrepos/valgrind.svg" alt="Packaging status" /></a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iai-callgrind"><a class="header" href="#iai-callgrind">Iai-Callgrind</a></h1>
<p>Iai-Callgrind is divided into the library <code>iai-callgrind</code> and the benchmark runner
<code>iai-callgrind-runner</code>.</p>
<h2 id="installation-of-the-library"><a class="header" href="#installation-of-the-library">Installation of the library</a></h2>
<p>To start with Iai-Callgrind, add the following to your <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml">[dev-dependencies]
iai-callgrind = "0.14.1"
</code></pre>
<p>or run</p>
<pre><code class="language-bash">cargo add --dev iai-callgrind@0.14.1
</code></pre>
<h2 id="installation-of-the-benchmark-runner"><a class="header" href="#installation-of-the-benchmark-runner">Installation of the benchmark runner</a></h2>
<p>To be able to run the benchmarks you'll also need the <code>iai-callgrind-runner</code>
binary installed somewhere in your <code>$PATH</code>. Otherwise, there is no need to
interact with <code>iai-callgrind-runner</code> as it is just an implementation detail.</p>
<h3 id="from-source"><a class="header" href="#from-source">From Source</a></h3>
<pre><code class="language-shell">cargo install --version 0.14.1 iai-callgrind-runner
</code></pre>
<p>There's also the possibility to install the binary somewhere else and point the
<code>IAI_CALLGRIND_RUNNER</code> environment variable to the absolute path of the
<code>iai-callgrind-runner</code> binary like so:</p>
<pre><code class="language-shell">cargo install --version 0.14.1 --root /tmp iai-callgrind-runner
IAI_CALLGRIND_RUNNER=/tmp/bin/iai-callgrind-runner cargo bench --bench my-bench
</code></pre>
<h3 id="binstall"><a class="header" href="#binstall">Binstall</a></h3>
<p>The <code>iai-callgrind-runner</code> binary is
<a href="https://github.com/iai-callgrind/iai-callgrind/releases/tag/v0.14.1">pre-built</a>
for most platforms supported by valgrind and easily installable with
<a href="https://github.com/cargo-bins/cargo-binstall">binstall</a></p>
<pre><code class="language-shell">cargo binstall iai-callgrind-runner@0.14.1
</code></pre>
<h2 id="updating"><a class="header" href="#updating">Updating</a></h2>
<p>When updating the <code>iai-callgrind</code> library, you'll also need to update
<code>iai-callgrind-runner</code> and vice-versa or else the benchmark runner will exit
with an error.</p>
<h3 id="in-the-github-ci"><a class="header" href="#in-the-github-ci">In the Github CI</a></h3>
<p>Since the <code>iai-callgrind-runner</code> version must match the <code>iai-callgrind</code> library
version it's best to automate this step in the CI. A job step in the github
actions CI could look like this</p>
<pre><code class="language-yaml">- name: Install iai-callgrind-runner
  run: |
    version=$(cargo metadata --format-version=1 |\
      jq '.packages[] | select(.name == "iai-callgrind").version' |\
      tr -d '"'
    )
    cargo install iai-callgrind-runner --version $version
</code></pre>
<p>Or, speed up the overall installation time with <code>binstall</code> using the
<a href="https://github.com/taiki-e/install-action">taiki-e/install-action</a></p>
<pre><code class="language-yaml">- uses: taiki-e/install-action@cargo-binstall
- name: Install iai-callgrind-runner
  run: |
    version=$(cargo metadata --format-version=1 |\
      jq '.packages[] | select(.name == "iai-callgrind").version' |\
      tr -d '"'
    )
    cargo binstall --no-confirm iai-callgrind-runner --version $version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<p>Iai-Callgrind can be used to benchmark the <a href="benchmarks/./library_benchmarks.html">library</a>
and <a href="benchmarks/./binary_benchmarks.html">binary</a> of your project's crates. Library and
binary benchmarks are treated differently by Iai-Callgrind and cannot be
intermixed in the same benchmark file. This is indeed a feature and helps
keeping things organized. Having different and multiple benchmark files for
library and binary benchmarks is no problem for Iai-Callgrind and is usually a
good idea anyway. Having benchmarks for different binaries in the same
benchmark file however is fully supported.</p>
<p>Head over to the <a href="benchmarks/./library_benchmarks/quickstart.html">Quickstart</a> section of
library benchmarks if you want to start benchmarking your library functions or
to the <a href="benchmarks/./binary_benchmarks/quickstart.html">Quickstart</a> section of binary
benchmarks if you want to start benchmarking your crate's binary (binaries).</p>
<h2 id="binary-benchmarks-vs-library-benchmarks"><a class="header" href="#binary-benchmarks-vs-library-benchmarks">Binary Benchmarks vs Library Benchmarks</a></h2>
<p>Almost all binary benchmarks can be written as library benchmarks. For example,
if you have a <code>main.rs</code> file of your binary, which basically looks like this</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">mod my_lib { pub fn run() {} }
</span>use my_lib::run;

fn main() {
    run();
}</code></pre></pre>
<p>you could also choose to benchmark the library function <code>my_lib::run</code> in a
library benchmark instead of the binary in a binary benchmark. There's no real
downside to either of the benchmark schemes and which scheme you want to use
heavily depends on the structure of your binary. As a maybe obvious rule of
thumb, micro-benchmarks of specific functions should go into library benchmarks
and macro-benchmarks into binary benchmarks. Generally, choose the closest
access point to the program point you actually want to benchmark.</p>
<p>You should always choose binary benchmarks over library benchmarks if you want
to benchmark the behaviour of the executable if the input comes from a pipe
since this feature is exclusive to binary benchmarks. See <a href="benchmarks/./binary_benchmarks/stdin_and_pipe.html">The Command's stdin
and simulating piped input</a> for more.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="library-benchmarks"><a class="header" href="#library-benchmarks">Library Benchmarks</a></h1>
<p>You want to dive into benchmarking your library? Best start with the
<a href="benchmarks/./library_benchmarks/quickstart.html">Quickstart</a> section and then go through the
examples in the other sections of this guide. If you need more examples see
<a href="benchmarks/./library_benchmarks/examples.html">here</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="important-default-behaviour"><a class="header" href="#important-default-behaviour">Important default behaviour</a></h1>
<p>The environment variables are cleared before running a library benchmark. Have a
look into the <a href="benchmarks/library_benchmarks/./configuration.html">Configuration</a> section if you need to change
that behavior. Iai-Callgrind sometimes deviates from the valgrind defaults which
are:</p>
<div class="table-wrapper"><table><thead><tr><th>Iai-Callgrind</th><th>Valgrind (v3.23)</th></tr></thead><tbody>
<tr><td><code>--trace-children=yes</code></td><td><code>--trace-children=no</code></td></tr>
<tr><td><code>--fair-sched=try</code></td><td><code>--fair-sched=no</code></td></tr>
<tr><td><code>--separate-threads=yes</code></td><td><code>--separate-threads=no</code></td></tr>
<tr><td><code>--cache-sim=yes</code></td><td><code>--cache-sim=no</code></td></tr>
</tbody></table>
</div>
<p>The thread and subprocess specific valgrind options enable tracing threads and
subprocesses basically but there's usually some additional configuration
necessary to trace the metrics of threads and subprocesses.</p>
<p>As show in the table above, the benchmarks run with cache simulation switched
on. This adds run time. If you don't need the cache metrics and estimation of
cycles, you can easily switch cache simulation off for example with:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::LibraryBenchmarkConfig;

LibraryBenchmarkConfig::default().callgrind_args(["--cache-sim=no"]);
<span class="boring">}</span></code></pre></pre>
<p>To switch off cache simulation for all benchmarks in the same file:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn fibonacci(a: u64) -&gt; u64 { a } }
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig
};
use std::hint::black_box;

#[library_benchmark]
fn bench_fibonacci() -&gt; u64 {
    black_box(my_lib::fibonacci(10))
}

library_benchmark_group!(name = fibonacci_group; benchmarks = bench_fibonacci);

<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default().callgrind_args(["--cache-sim=no"]);
    library_benchmark_groups = fibonacci_group
);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="quickstart"><a class="header" href="#quickstart">Quickstart</a></h1>
<p>Create a file <code>$WORKSPACE_ROOT/benches/library_benchmark.rs</code> and add</p>
<pre><code class="language-toml">[[bench]]
name = "library_benchmark"
harness = false
</code></pre>
<p>to your <code>Cargo.toml</code>. <code>harness = false</code>, tells <code>cargo</code> to not use the default
rust benchmarking harness which is important because Iai-Callgrind has an own
benchmarking harness.</p>
<p>Then copy the following content into this file:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

fn fibonacci(n: u64) -&gt; u64 {
    match n {
        0 =&gt; 1,
        1 =&gt; 1,
        n =&gt; fibonacci(n - 1) + fibonacci(n - 2),
    }
}

#[library_benchmark]
#[bench::short(10)]
#[bench::long(30)]
fn bench_fibonacci(value: u64) -&gt; u64 {
    black_box(fibonacci(value))
}

library_benchmark_group!(
    name = bench_fibonacci_group;
    benchmarks = bench_fibonacci
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bench_fibonacci_group);
<span class="boring">}</span></code></pre></pre>
<p>Now, that your first library benchmark is set up, you can run it with</p>
<pre><code class="language-shell">cargo bench
</code></pre>
<p>and should see something like the below</p>
<pre><code class="hljs"><span style="color:#0A0">library_benchmark::bench_fibonacci_group::bench_fibonacci</span> <span style="color:#0AA">short</span><span style="color:#0AA">:</span><b><span style="color:#00A">10</span></b>
  Instructions:     <b>           1734</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>           2359</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              0</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              3</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>           2362</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>           2464</b>|N/A             (<span style="color:#555">*********</span>)
<span style="color:#0A0">library_benchmark::bench_fibonacci_group::bench_fibonacci</span> <span style="color:#0AA">long</span><span style="color:#0AA">:</span><b><span style="color:#00A">30</span></b>
  Instructions:     <b>       26214734</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>       35638616</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              2</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>       35638622</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>       35638766</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>In addition, you'll find the callgrind output and the output of other valgrind
tools in <code>target/iai</code>, if you want to investigate further with a tool like
<code>callgrind_annotate</code> etc.</p>
<p>When running the same benchmark again, the output will report the differences
between the current and the previous run. Say you've made change to the
<code>fibonacci</code> function, then you may see something like this:</p>
<pre><code class="hljs"><span style="color:#0A0">library_benchmark::bench_fibonacci_group::bench_fibonacci</span> <span style="color:#0AA">short</span><span style="color:#0AA">:</span><b><span style="color:#00A">10</span></b>
  Instructions:     <b>           2805</b>|1734            (<b><span style="color:#F55">+61.7647%</span></b>) [<b><span style="color:#F55">+1.61765x</span></b>]
  L1 Hits:          <b>           3815</b>|2359            (<b><span style="color:#F55">+61.7211%</span></b>) [<b><span style="color:#F55">+1.61721x</span></b>]
  L2 Hits:          <b>              0</b>|0               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              3</b>|3               (<span style="color:#555">No change</span>)
  Total read+write: <b>           3818</b>|2362            (<b><span style="color:#F55">+61.6427%</span></b>) [<b><span style="color:#F55">+1.61643x</span></b>]
  Estimated Cycles: <b>           3920</b>|2464            (<b><span style="color:#F55">+59.0909%</span></b>) [<b><span style="color:#F55">+1.59091x</span></b>]
<span style="color:#0A0">library_benchmark::bench_fibonacci_group::bench_fibonacci</span> <span style="color:#0AA">long</span><span style="color:#0AA">:</span><b><span style="color:#00A">30</span></b>
  Instructions:     <b>       16201597</b>|26214734        (<b><span style="color:#42c142">-38.1966%</span></b>) [<b><span style="color:#42c142">-1.61803x</span></b>]
  L1 Hits:          <b>       22025876</b>|35638616        (<b><span style="color:#42c142">-38.1966%</span></b>) [<b><span style="color:#42c142">-1.61803x</span></b>]
  L2 Hits:          <b>              2</b>|2               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              4</b>|4               (<span style="color:#555">No change</span>)
  Total read+write: <b>       22025882</b>|35638622        (<b><span style="color:#42c142">-38.1966%</span></b>) [<b><span style="color:#42c142">-1.61803x</span></b>]
  Estimated Cycles: <b>       22026026</b>|35638766        (<b><span style="color:#42c142">-38.1964%</span></b>) [<b><span style="color:#42c142">-1.61803x</span></b>]</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="anatomy-of-a-library-benchmark"><a class="header" href="#anatomy-of-a-library-benchmark">Anatomy of a library benchmark</a></h1>
<p>We're reusing our example from the <a href="benchmarks/library_benchmarks/./quickstart.html">Quickstart</a> section.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

fn fibonacci(n: u64) -&gt; u64 {
    match n {
        0 =&gt; 1,
        1 =&gt; 1,
        n =&gt; fibonacci(n - 1) + fibonacci(n - 2),
    }
}

#[library_benchmark]
#[bench::short(10)]
#[bench::long(30)]
fn bench_fibonacci(value: u64) -&gt; u64 {
    black_box(fibonacci(value))
}

library_benchmark_group!(
    name = bench_fibonacci_group;
    benchmarks = bench_fibonacci
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bench_fibonacci_group);
<span class="boring">}</span></code></pre></pre>
<p>First of all, you need a public function in your library which you want to
benchmark. In this example this is the <code>fibonacci</code> function which, for the sake
of simplicity, lives in the benchmark file itself but doesn't have to. If it
had been located in <code>my_lib::fibonacci</code>, you simply import that function
with <code>use my_lib::fibonacci</code> and go on as shown above. Next, you need a
<code>library_benchmark_group!</code> in which you specify the names of the benchmark
functions. Finally, the benchmark harness is created by the <code>main!</code> macro.</p>
<h2 id="the-benchmark-function"><a class="header" href="#the-benchmark-function">The benchmark function</a></h2>
<p>The benchmark function has to be annotated with the
<a href="benchmarks/library_benchmarks/./macros.html"><code>#[library_benchmark]</code></a> attribute. The
<a href="benchmarks/library_benchmarks/./macros.html"><code>#[bench]</code></a> attribute is an inner attribute of the
<code>#[library_benchmark]</code> attribute. It consists of a mandatory id (the <code>ID</code> part
in <code>#[bench::ID(/* ... */)]</code>) and in its most basic form, an optional list of
arguments which are passed to the benchmark function as parameters. Naturally,
the parameters of the benchmark function must match the argument list of the
<code>#[bench]</code> attribute. It is always a good idea to return something from the
benchmark function, here it is the computed <code>u64</code> value from the <code>fibonacci</code>
function wrapped in a <code>black_box</code>. See the docs of
<a href="https://doc.rust-lang.org/std/hint/fn.black_box.html"><code>std::hint::black_box</code></a>
for more information about its usage. Simply put, <em>all</em> values and variables in
the benchmarking function (but not in your library function) need to be wrapped
in a <code>black_box</code> except for the input parameters (here <code>value</code>) because
Iai-Callgrind already does that. But, it is no error to <code>black_box</code> the <code>value</code>
again.</p>
<p>The <code>bench</code> attribute takes any expression which includes function calls. The
following would have worked too and is one way to avoid the costs of the setup
code being attributed to the benchmarked function.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

fn some_setup_func(value: u64) -&gt; u64 {
    value + 10
}

fn fibonacci(n: u64) -&gt; u64 {
    match n {
        0 =&gt; 1,
        1 =&gt; 1,
        n =&gt; fibonacci(n - 1) + fibonacci(n - 2),
    }
}

#[library_benchmark]
#[bench::short(10)]
// Note the usage of the `some_setup_func` in the argument list of this #[bench]
#[bench::long(some_setup_func(20))]
fn bench_fibonacci(value: u64) -&gt; u64 {
    black_box(fibonacci(value))
}

library_benchmark_group!(
   name = bench_fibonacci_group;
   benchmarks = bench_fibonacci
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bench_fibonacci_group);
<span class="boring">}</span></code></pre></pre>
<p>The perhaps most crucial part in setting up library benchmarks is to keep the
body of benchmark functions clean from any setup or teardown code. There are
other ways to avoid setup and teardown code in the benchmark function,
which are discussed in full detail in the <a href="benchmarks/library_benchmarks/./setup_and_teardown.html">setup and
teardown</a> section.</p>
<h2 id="the-group"><a class="header" href="#the-group">The group</a></h2>
<p>The name of the benchmark functions, here the only benchmark function
<code>bench_fibonacci</code>, which should be benchmarked need to be specified in a
<code>library_benchmark_group!</code> in the <code>benchmarks</code> parameter. You can create as many
groups as you like, and you can use it to organize related benchmarks. Each group
needs a unique <code>name</code>.</p>
<h2 id="the-main-macro"><a class="header" href="#the-main-macro">The main macro</a></h2>
<p>Each group you want to be benchmarked needs to be specified in the
<code>library_benchmark_groups</code> parameter of the <code>main!</code> macro and you're all set.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-macros-in-more-detail"><a class="header" href="#the-macros-in-more-detail">The macros in more detail</a></h1>
<p>This section is a brief reference to all the macros available in library
benchmarks. Feel free to come back here from other sections if you need a
reference. For the complete documentation of each macro see the <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/">api
Documentation</a>.</p>
<p>For the following examples it is assumed that there is a file <code>lib.rs</code> in a
crate named <code>my_lib</code> with the following content:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn bubble_sort(mut array: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    for i in 0..array.len() {
        for j in 0..array.len() - i - 1 {
            if array[j + 1] &lt; array[j] {
                array.swap(j, j + 1);
            }
        }
    }
    array
}
<span class="boring">}</span></code></pre></pre>
<h2 id="the-library_benchmark-attribute"><a class="header" href="#the-library_benchmark-attribute">The <code>#[library_benchmark]</code> attribute</a></h2>
<p>This attribute needs to be present on all benchmark functions specified in the
<a href="benchmarks/library_benchmarks/macros.html#the-library_benchmark_group-macro"><code>library_benchmark_group</code></a>. The benchmark
function can then be further annotated with the inner
<a href="benchmarks/library_benchmarks/macros.html#the-bench-attribute"><code>#[bench]</code></a> or <a href="benchmarks/library_benchmarks/macros.html#the-benches-attribute"><code>#[benches]</code></a>
attributes.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

#[library_benchmark]
#[bench::one(vec![1])]
#[benches::multiple(vec![1, 2], vec![1, 2, 3], vec![1, 2, 3, 4])]
fn bench_bubble_sort(values: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(values))
}

library_benchmark_group!(name = bubble_sort_group; benchmarks = bench_bubble_sort);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bubble_sort_group);
<span class="boring">}</span></code></pre></pre>
<p>The following parameters are accepted:</p>
<ul>
<li><code>config</code>: Takes a
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a></li>
<li><code>setup</code>: A global setup function which is applied to all following <a href="benchmarks/library_benchmarks/macros.html#the-bench-attribute"><code>#[bench]</code></a>
and <a href="benchmarks/library_benchmarks/macros.html#the-benches-attribute"><code>#[benches]</code></a> attributes if not overwritten by a <code>setup</code> parameter of these
attributes.</li>
<li><code>teardown</code>: Similar to <code>setup</code> but takes a global <code>teardown</code> function.</li>
</ul>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{
    library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
    OutputFormat
};
use std::hint::black_box;

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .output_format(OutputFormat::default()
           .truncate_description(None)
        )
)]
#[bench::one(vec![1])]
fn bench_bubble_sort(values: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(values))
}

library_benchmark_group!(name = bubble_sort_group; benchmarks = bench_bubble_sort);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bubble_sort_group);
<span class="boring">}</span></code></pre></pre>
<h3 id="the-bench-attribute"><a class="header" href="#the-bench-attribute">The <code>#[bench]</code> attribute</a></h3>
<p>The basic structure is <code>#[bench::some_id(/* parameters */)]</code>. The part after the
<code>::</code> must be an id unique within the same <code>#[library_benchmark]</code>. This attribute
accepts the following parameters:</p>
<ul>
<li><code>args</code>: A tuple with a list of arguments which are passed to the
benchmark function. The parentheses also need to be present if there is only a
single argument (<code>#[bench::my_id(args = (10))]</code>).</li>
<li><code>config</code>: Accepts a
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a></li>
<li><code>setup</code>: A function which takes the arguments specified in the <code>args</code>
parameter and passes its return value to the benchmark function.</li>
<li><code>teardown</code>: A function which takes the return value of the benchmark function.</li>
</ul>
<p>If no other parameters besides <code>args</code> are present you can simply pass the
arguments as a list of values. So, instead of <code>#[bench::my_id(args = (10, 20))]</code>, you could also use the shorter <code>#[bench::my_id(10, 20)]</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig};
use std::hint::black_box;

// This function is used to create a worst case array we want to sort with our implementation of
// bubble sort
pub fn worst_case(start: i32) -&gt; Vec&lt;i32&gt; {
    if start.is_negative() {
        (start..0).rev().collect()
    } else {
        (0..start).rev().collect()
    }
}

#[library_benchmark]
#[bench::one(vec![1])]
#[bench::worst_two(args = (vec![2, 1]))]
#[bench::worst_four(args = (4), setup = worst_case)]
fn bench_bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(value))
}

library_benchmark_group!(name = bubble_sort_group; benchmarks = bench_bubble_sort);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bubble_sort_group);
<span class="boring">}</span></code></pre></pre>
<h3 id="the-benches-attribute"><a class="header" href="#the-benches-attribute">The <code>#[benches]</code> attribute</a></h3>
<p>This attribute is used to specify multiple benchmarks at once. It accepts the
same parameters as the <a href="benchmarks/library_benchmarks/macros.html#the-bench-attribute"><code>#[bench]</code></a> attribute: <code>args</code>,
<code>config</code>, <code>setup</code> and <code>teardown</code> and additionally the <code>file</code> parameter which is
explained in detail <a href="benchmarks/library_benchmarks/./multiple_benches.html">here</a>. In contrast to the <code>args</code>
parameter in <a href="benchmarks/library_benchmarks/macros.html#the-bench-attribute"><code>#[bench]</code></a>, <code>args</code> takes an array of
arguments.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig};
use std::hint::black_box;

pub fn worst_case(start: i32) -&gt; Vec&lt;i32&gt; {
    if start.is_negative() {
        (start..0).rev().collect()
    } else {
        (0..start).rev().collect()
    }
}

#[library_benchmark]
#[benches::worst_two_and_three(args = [vec![2, 1], vec![3, 2, 1]])]
#[benches::worst_four_to_nine(args = [4, 5, 6, 7, 8, 9], setup = worst_case)]
fn bench_bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(value))
}

library_benchmark_group!(name = bubble_sort_group; benchmarks = bench_bubble_sort);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bubble_sort_group);
<span class="boring">}</span></code></pre></pre>
<h2 id="the-library_benchmark_group-macro"><a class="header" href="#the-library_benchmark_group-macro">The library_benchmark_group! macro</a></h2>
<p>The <code>library_benchmark_group</code> macro accepts the following parameters (in this
order and separated by a semicolon):</p>
<ul>
<li><strong><code>name</code></strong> (mandatory): A unique name used to identify the group for the
<code>main!</code> macro</li>
<li><strong><code>config</code></strong> (optional): A
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a>
which is applied to all benchmarks within the same group.</li>
<li><strong><code>compare_by_id</code></strong> (optional): The default is false. If true, all benches in
the benchmark functions specified in the <code>benchmarks</code> parameter are compared
with each other as long as the ids (the part after the <code>::</code> in
<code>#[bench::id(...)]</code>) match. See also <a href="benchmarks/library_benchmarks/./compare_by_id.html">Comparing benchmark
functions</a></li>
<li><strong><code>setup</code></strong> (optional): A setup function or any valid expression which is run
before all benchmarks of this group</li>
<li><strong><code>teardown</code></strong> (optional): A teardown function or any valid expression which
is run after all benchmarks of this group</li>
<li><strong><code>benchmarks</code></strong> (mandatory): A list of comma separated paths of benchmark
functions which are annotated with <code>#[library_benchmark]</code></li>
</ul>
<p>Note the <code>setup</code> and <code>teardown</code> parameters are different to the ones of
<code>#[library_benchmark]</code>, <code>#[bench]</code> and <code>#[benches]</code>. They accept an expression
or function call as in <code>setup = group_setup_function()</code>. Also, these <code>setup</code> and
<code>teardown</code> functions are not overridden by the ones from any of the before
mentioned attributes.</p>
<h2 id="the-main-macro-1"><a class="header" href="#the-main-macro-1">The main! macro</a></h2>
<p>This macro is the entry point for Iai-Callgrind and creates the benchmark
harness. It accepts the following top-level arguments in this order (separated
by a semicolon):</p>
<ul>
<li><strong><code>config</code></strong> (optional): Optionally specify a
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a></li>
<li><strong><code>setup</code></strong> (optional): A setup function or any valid expression which is run
before all benchmarks</li>
<li><strong><code>teardown</code></strong> (optional): A setup function or any valid expression which is
run after all benchmarks</li>
<li><strong><code>library_benchmark_groups</code></strong> (mandatory): The name of one or more library
benchmark groups. Multiple names are separated by a comma.</li>
</ul>
<p>Like the <code>setup</code> and <code>teardown</code> of the
<a href="benchmarks/library_benchmarks/macros.html#the-library_benchmark_group-macro"><code>library_benchmark_group</code></a>, these
parameters accept an expression and are not overridden by the <code>setup</code> and
<code>teardown</code> of the <code>library_benchmark_group</code>, <code>#[library_benchmark]</code>, <code>#[bench]</code>
or <code>#[benches]</code> attribute.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="setup-and-teardown"><a class="header" href="#setup-and-teardown">setup and teardown</a></h1>
<p><code>setup</code> and <code>teardown</code> are your bread and butter in library benchmarks. The
benchmark functions need to be as clean as possible and almost always only
contain the function call to the function of your library which you want to
benchmark.</p>
<h2 id="setup"><a class="header" href="#setup">Setup</a></h2>
<p>In an ideal world you don't need any setup code, and you can pass arguments to
the function as they are.</p>
<p>But, for example if a function expects a <code>File</code> and not a <code>&amp;str</code> with the path
to the file you need <code>setup</code> code. Iai-Callgrind has an easy-to-use system in
place to allow you to run any setup code before the function is executed and
this <code>setup</code> code is not attributed to the metrics of the benchmark.</p>
<p>If the <code>setup</code> parameter is specified, the <code>setup</code> function takes the arguments
from the <code>#[bench]</code> (or <code>#[benches]</code>) attributes and the benchmark function
receives the return value of the <code>setup</code> function as parameter. This is a small
indirection with great effect. The effect is best shown with an example:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn count_bytes_fast(_file: std::fs::File) -&gt; u64 { 1 } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};

use std::hint::black_box;
use std::path::PathBuf;
use std::fs::File;

fn open_file(path: &amp;str) -&gt; File {
    File::open(path).unwrap()
}

#[library_benchmark]
#[bench::first(args = ("path/to/file"), setup = open_file)]
fn count_bytes_fast(file: File) -&gt; u64 {
    black_box(my_lib::count_bytes_fast(file))
}

library_benchmark_group!(name = my_group; benchmarks = count_bytes_fast);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>You can actually see the effect of using a setup function in the output of the
benchmark. Let's assume the above benchmark is in a file
<code>benches/my_benchmark.rs</code>, then running</p>
<pre><code class="language-shell">IAI_CALLGRIND_NOCAPTURE=true cargo bench
</code></pre>
<p>result in the benchmark output like below.</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::count_bytes_fast</span> <span style="color:#0AA">first</span><span style="color:#0AA">:</span><b><span style="color:#00A">open_file("path/to/file")</span></b>
  Instructions:     <b>        1630162</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>        2507933</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              2</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>             11</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>        2507946</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>        2508328</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>The description in the headline contains <code>open_file("path/to/file")</code>, your setup
function <code>open_file</code> with the value of the parameter it is called with.</p>
<p>If you need to specify the same <code>setup</code> function for all (or almost all)
<code>#[bench]</code> and <code>#[benches]</code> in a <code>#[library_benchmark]</code> you can use the <code>setup</code>
parameter of the <code>#[library_benchmark]</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn count_bytes_fast(_file: std::fs::File) -&gt; u64 { 1 } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};

use std::hint::black_box;
use std::path::PathBuf;
use std::fs::File;
use std::io::{Seek, SeekFrom};

fn open_file(path: &amp;str) -&gt; File {
    File::open(path).unwrap()
}

fn open_file_with_offset(path: &amp;str, offset: u64) -&gt; File {
    let mut file = File::open(path).unwrap();
    file.seek(SeekFrom::Start(offset)).unwrap();
    file
}

#[library_benchmark(setup = open_file)]
#[bench::small("path/to/small")]
#[bench::big("path/to/big")]
#[bench::with_offset(args = ("path/to/big", 100), setup = open_file_with_offset)]
fn count_bytes_fast(file: File) -&gt; u64 {
    black_box(my_lib::count_bytes_fast(file))
}

library_benchmark_group!(name = my_group; benchmarks = count_bytes_fast);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The above will use the <code>open_file</code> function in the <code>small</code> and <code>big</code> benchmarks
and the <code>open_file_with_offset</code> function in the <code>with_offset</code> benchmark.</p>
<h2 id="teardown"><a class="header" href="#teardown">Teardown</a></h2>
<p>What about <code>teardown</code> and why should you use it? Usually the <code>teardown</code> isn't
needed but for example if you intend to make the result from the benchmark
visible in the benchmark output, the <code>teardown</code> is the perfect place to do so.</p>
<p>The <code>teardown</code> function takes the return value of the benchmark function as its
argument:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn count_bytes_fast(_file: std::fs::File) -&gt; u64 { 1 } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};

use std::hint::black_box;
use std::path::PathBuf;
use std::fs::File;

fn open_file(path: &amp;str) -&gt; File {
    File::open(path).unwrap()
}

fn print_bytes_read(num_bytes: u64) {
    println!("bytes read: {num_bytes}");
}

#[library_benchmark]
#[bench::first(
    args = ("path/to/big"),
    setup = open_file,
    teardown = print_bytes_read
)]
fn count_bytes_fast(file: File) -&gt; u64 {
    black_box(my_lib::count_bytes_fast(file))
}

library_benchmark_group!(name = my_group; benchmarks = count_bytes_fast);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Note Iai-Callgrind captures all output per default. In order to actually see the
output of the benchmark, <code>setup</code> and <code>teardown</code> functions, it is required to run
the benchmarks with the flag <code>--nocapture</code> or set the environment variable
<code>IAI_CALLGRIND_NOCAPTURE=true</code>. Let's assume the above benchmark is in a file
<code>benches/my_benchmark.rs</code>, then running</p>
<pre><code class="language-shell">IAI_CALLGRIND_NOCAPTURE=true cargo bench
</code></pre>
<p>results in output like the below</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::count_bytes_fast</span> <span style="color:#0AA">first</span><span style="color:#0AA">:</span><b><span style="color:#00A">open_file("path/to/big")</span></b>
bytes read: 25078
<span style="color:#A50">-</span> <span style="color:#A50">end of stdout/stderr</span>
  Instructions:     <b>        1630162</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>        2507931</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              2</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>             13</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>        2507946</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>        2508396</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>The output of the <code>teardown</code> function is now visible in the benchmark output
above the <code>- end of stdout/stderr</code> line.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="specifying-multiple-benches-at-once"><a class="header" href="#specifying-multiple-benches-at-once">Specifying multiple benches at once</a></h1>
<p>Multiple benches can be specified at once with the
<a href="benchmarks/library_benchmarks/macros.html#the-benches-attribute"><code>#[benches]</code></a> attribute.</p>
<h2 id="the-benches-attribute-in-more-detail"><a class="header" href="#the-benches-attribute-in-more-detail">The <code>#[benches]</code> attribute in more detail</a></h2>
<p>Let's start with an example:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;
use my_lib::bubble_sort;

fn setup_worst_case_array(start: i32) -&gt; Vec&lt;i32&gt; {
    if start.is_negative() {
        (start..0).rev().collect()
    } else {
        (0..start).rev().collect()
    }
}

#[library_benchmark]
#[benches::multiple(vec![1], vec![5])]
#[benches::with_setup(args = [1, 5], setup = setup_worst_case_array)]
fn bench_bubble_sort_with_benches_attribute(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(bubble_sort(input))
}

library_benchmark_group!(name = my_group; benchmarks = bench_bubble_sort_with_benches_attribute);
<span class="boring">fn main () {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Usually the <code>arguments</code> are passed directly to the benchmarking function as it
can be seen in the <code>#[benches::multiple(/* arguments */)]</code> case. In
<code>#[benches::with_setup(/* ... */)]</code>, the arguments are passed to the <code>setup</code> function
instead. The above <code>#[library_benchmark]</code> is pretty much the same as</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(value: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { value } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;
use my_lib::bubble_sort;

fn setup_worst_case_array(start: i32) -&gt; Vec&lt;i32&gt; {
    if start.is_negative() {
        (start..0).rev().collect()
    } else {
        (0..start).rev().collect()
    }
}

#[library_benchmark]
#[bench::multiple_0(vec![1])]
#[bench::multiple_1(vec![5])]
#[bench::with_setup_0(setup_worst_case_array(1))]
#[bench::with_setup_1(setup_worst_case_array(5))]
fn bench_bubble_sort_with_benches_attribute(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(bubble_sort(input))
}

library_benchmark_group!(name = my_group; benchmarks = bench_bubble_sort_with_benches_attribute);
<span class="boring">fn main () {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>but a lot more concise especially if a lot of values are passed to the same
<code>setup</code> function.</p>
<h3 id="the-file-parameter"><a class="header" href="#the-file-parameter">The <code>file</code> parameter</a></h3>
<p>Reading inputs from a file allows for example sharing the same inputs between
different benchmarking frameworks like <code>criterion</code> or if you simply have a long
list of inputs you might find it more convenient to read them from a file.</p>
<p>The <code>file</code> parameter, exclusive to the <code>#[benches]</code> attribute, does exactly that
and reads the specified file line by line creating a benchmark from each line.
The line is passed to the benchmark function as <code>String</code> or if the <code>setup</code>
parameter is also present to the <code>setup</code> function. A small example assuming you
have a file <code>benches/inputs</code> (relative paths are interpreted to the workspace
root) with the following content</p>
<pre><code class="language-text">1
11
111
</code></pre>
<p>then</p>
<pre><code class="language-rust ignore"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn string_to_u64(value: String) -&gt; Result&lt;u64, String&gt; { Ok(1) } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

#[library_benchmark]
#[benches::from_file(file = "benches/inputs")]
fn some_bench(line: String) -&gt; Result&lt;u64, String&gt; {
    black_box(my_lib::string_to_u64(line))
}

library_benchmark_group!(name = my_group; benchmarks = some_bench);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre>
<p>The above is roughly equivalent to the following but with the <code>args</code> parameter</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn string_to_u64(value: String) -&gt; Result&lt;u64, String&gt; { Ok(1) } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

#[library_benchmark]
#[benches::from_args(args = [1.to_string(), 11.to_string(), 111.to_string()])]
fn some_bench(line: String) -&gt; Result&lt;u64, String&gt; {
    black_box(my_lib::string_to_u64(line))
}

library_benchmark_group!(name = my_group; benchmarks = some_bench);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The true power of the <code>file</code> parameter comes with the <code>setup</code> function because
you can format the lines in the file as you like and convert each line in the
<code>setup</code> function to the format as you need it in the benchmark. For example if
you decided to go with a csv like format in the file <code>benches/inputs</code></p>
<pre><code class="language-text">255;255;255
0;0;0
</code></pre>
<p>and your library has a function which converts from RGB to HSV color space:</p>
<pre><code class="language-rust ignore"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn rgb_to_hsv(a: u8, b: u8, c:u8) -&gt; (u16, u8, u8) { (a.into(), b, c) } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

fn decode_line(line: String) -&gt; (u8, u8, u8) {
    if let &amp;[a, b, c] = line.split(";")
        .map(|s| s.parse::&lt;u8&gt;().unwrap())
        .collect::&lt;Vec&lt;u8&gt;&gt;()
        .as_slice() 
    {
        (a, b, c)
    } else {
        panic!("Wrong input format in line '{line}'");
    }
}

#[library_benchmark]
#[benches::from_file(file = "benches/inputs", setup = decode_line)]
fn some_bench((a, b, c): (u8, u8, u8)) -&gt; (u16, u8, u8) {
    black_box(my_lib::rgb_to_hsv(black_box(a), black_box(b), black_box(c)))
}

library_benchmark_group!(name = my_group; benchmarks = some_bench);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generic-benchmark-functions"><a class="header" href="#generic-benchmark-functions">Generic benchmark functions</a></h1>
<p>Benchmark functions can be generic. And <code>setup</code> and <code>teardown</code> functions, too.
There's actually not much more to say about it since generic benchmark (<code>setup</code>
and <code>teardown</code>) functions behave exactly the same way as you would expect it
from any other generic function.</p>
<p>However, there is a common pitfall. If you have a function
<code>count_lines_in_file_fast</code> which expects as parameter a <code>PathBuf</code> and although
it is convenient especially when you have to specify many paths, don't do this:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn count_lines_in_file_fast(_path: std::path::PathBuf) -&gt; u64 { 1 } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};

use std::hint::black_box;
use std::path::PathBuf;

#[library_benchmark]
#[bench::first("path/to/file")]
fn generic_bench&lt;T&gt;(path: T) -&gt; u64 where T: Into&lt;PathBuf&gt; {
    black_box(my_lib::count_lines_in_file_fast(black_box(path.into())))
}

library_benchmark_group!(name = my_group; benchmarks = generic_bench);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Since <code>path.into()</code> is called in the benchmark function itself, the conversion
from a <code>&amp;str</code> to a <code>PathBuf</code> is attributed to the benchmark metrics. This is
almost never what you intended. You should instead convert the argument to a
<code>PathBuf</code> in a generic <code>setup</code> function like that:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn count_lines_in_file_fast(_path: std::path::PathBuf) -&gt; u64 { 1 } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};

use std::hint::black_box;
use std::path::PathBuf;

fn convert_to_pathbuf&lt;T&gt;(path: T) -&gt; PathBuf where T: Into&lt;PathBuf&gt; {
    path.into()
}

#[library_benchmark]
#[bench::first(args = ("path/to/file"), setup = convert_to_pathbuf)]
fn not_generic_anymore(path: PathBuf) -&gt; u64 {
    black_box(my_lib::count_lines_in_file_fast(path))
}

library_benchmark_group!(name = my_group; benchmarks = not_generic_anymore);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>That way you can still enjoy the convenience to use string literals instead of
<code>PathBuf</code> in your <code>#[bench]</code> (or <code>#[benches]</code>) arguments and have clean
benchmark metrics.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD025 MD042 MD033 -->
<h1 id="comparing-benchmark-functions"><a class="header" href="#comparing-benchmark-functions">Comparing benchmark functions</a></h1>
<p>Comparing benchmark functions is supported via the optional
<code>library_benchmark_group!</code> argument <code>compare_by_id</code> (The default value for
<code>compare_by_id</code> is <code>false</code>). Only benches with the same <code>id</code> are compared, which
allows to single out cases which don't need to be compared. In the following
example, the <code>case_3</code> and <code>multiple</code> bench are compared with each other in
addition to the usual comparison with the previous run:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

#[library_benchmark]
#[bench::case_3(vec![1, 2, 3])]
#[benches::multiple(args = [vec![1, 2], vec![1, 2, 3, 4]])]
fn bench_bubble_sort_best_case(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(input))
}

#[library_benchmark]
#[bench::case_3(vec![3, 2, 1])]
#[benches::multiple(args = [vec![2, 1], vec![4, 3, 2, 1]])]
fn bench_bubble_sort_worst_case(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(input))
}

library_benchmark_group!(
    name = bench_bubble_sort;
    compare_by_id = true;
    benchmarks = bench_bubble_sort_best_case, bench_bubble_sort_worst_case
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = bench_bubble_sort);
<span class="boring">}</span></code></pre></pre>
<p>Note if <code>compare_by_id</code> is <code>true</code>, all benchmark functions are compared with
each other, so you are not limited to two benchmark functions per comparison
group.</p>
<p>Here's the benchmark output of the above example to see what is happening:</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_best_case</span> <span style="color:#0AA">case_2</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [1, 2]</span></b>
  Instructions:     <b>             63</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>             86</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>             91</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            231</b>|N/A             (<span style="color:#555">*********</span>)
<span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_best_case</span> <span style="color:#0AA">multiple_0</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [1, 2, 3]</span></b>
  Instructions:     <b>             94</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            123</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            128</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            268</b>|N/A             (<span style="color:#555">*********</span>)
<span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_best_case</span> <span style="color:#0AA">multiple_1</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [1, 2, 3, 4]</span></b>
  Instructions:     <b>            136</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            174</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            179</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            319</b>|N/A             (<span style="color:#555">*********</span>)
<span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_worst_case</span> <span style="color:#0AA">case_2</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [2, 1]</span></b>
  Instructions:     <b>             66</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>             91</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>             96</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            236</b>|N/A             (<span style="color:#555">*********</span>)
  <b><span style="color:#A50">Comparison with</span></b> <span style="color:#0A0">bubble_sort_best_case</span> <span style="color:#0AA">case_2</span>:<b><span style="color:#00A">vec! [1, 2]</span></b>
  Instructions:     <b>             63</b>|66              (<b><span style="color:#42c142">-4.54545%</span></b>) [<b><span style="color:#42c142">-1.04762x</span></b>]
  L1 Hits:          <b>             86</b>|91              (<b><span style="color:#42c142">-5.49451%</span></b>) [<b><span style="color:#42c142">-1.05814x</span></b>]
  L2 Hits:          <b>              1</b>|1               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              4</b>|4               (<span style="color:#555">No change</span>)
  Total read+write: <b>             91</b>|96              (<b><span style="color:#42c142">-5.20833%</span></b>) [<b><span style="color:#42c142">-1.05495x</span></b>]
  Estimated Cycles: <b>            231</b>|236             (<b><span style="color:#42c142">-2.11864%</span></b>) [<b><span style="color:#42c142">-1.02165x</span></b>]
<span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_worst_case</span> <span style="color:#0AA">multiple_0</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [3, 2, 1]</span></b>
  Instructions:     <b>            103</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            138</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            143</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            283</b>|N/A             (<span style="color:#555">*********</span>)
  <b><span style="color:#A50">Comparison with</span></b> <span style="color:#0A0">bubble_sort_best_case</span> <span style="color:#0AA">multiple_0</span>:<b><span style="color:#00A">vec! [1, 2, 3]</span></b>
  Instructions:     <b>             94</b>|103             (<b><span style="color:#42c142">-8.73786%</span></b>) [<b><span style="color:#42c142">-1.09574x</span></b>]
  L1 Hits:          <b>            123</b>|138             (<b><span style="color:#42c142">-10.8696%</span></b>) [<b><span style="color:#42c142">-1.12195x</span></b>]
  L2 Hits:          <b>              1</b>|1               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              4</b>|4               (<span style="color:#555">No change</span>)
  Total read+write: <b>            128</b>|143             (<b><span style="color:#42c142">-10.4895%</span></b>) [<b><span style="color:#42c142">-1.11719x</span></b>]
  Estimated Cycles: <b>            268</b>|283             (<b><span style="color:#42c142">-5.30035%</span></b>) [<b><span style="color:#42c142">-1.05597x</span></b>]
<span style="color:#0A0">my_benchmark::bubble_sort_group::bubble_sort_worst_case</span> <span style="color:#0AA">multiple_1</span><span style="color:#0AA">:</span><b><span style="color:#00A">vec! [4, 3, 2, 1]</span></b>
  Instructions:     <b>            154</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            204</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              4</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            209</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            349</b>|N/A             (<span style="color:#555">*********</span>)
  <b><span style="color:#A50">Comparison with</span></b> <span style="color:#0A0">bubble_sort_best_case</span> <span style="color:#0AA">multiple_1</span>:<b><span style="color:#00A">vec! [1, 2, 3, 4]</span></b>
  Instructions:     <b>            136</b>|154             (<b><span style="color:#42c142">-11.6883%</span></b>) [<b><span style="color:#42c142">-1.13235x</span></b>]
  L1 Hits:          <b>            174</b>|204             (<b><span style="color:#42c142">-14.7059%</span></b>) [<b><span style="color:#42c142">-1.17241x</span></b>]
  L2 Hits:          <b>              1</b>|1               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              4</b>|4               (<span style="color:#555">No change</span>)
  Total read+write: <b>            179</b>|209             (<b><span style="color:#42c142">-14.3541%</span></b>) [<b><span style="color:#42c142">-1.16760x</span></b>]
  Estimated Cycles: <b>            319</b>|349             (<b><span style="color:#42c142">-8.59599%</span></b>) [<b><span style="color:#42c142">-1.09404x</span></b>]</code></pre>
<p>The procedure of the comparison algorithm:</p>
<ol>
<li>Run all benches in the first benchmark function</li>
<li>Run the first bench in the second benchmark function and if there is a bench
in the first benchmark function with the same id compare them</li>
<li>Run the second bench in the second benchmark function ...</li>
<li>...</li>
<li>Run the first bench in the third benchmark function and if there is a bench
in the first benchmark function with the same id compare them. If there is a
bench with the same id in the second benchmark function compare them.</li>
<li>Run the second bench in the third benchmark function ...</li>
<li>and so on ... until all benches are compared with each other</li>
</ol>
<p>Neither the order nor the amount of benches within the benchmark functions
matters, so it is not strictly necessary to mirror the bench ids of the first
benchmark function in the second, third, etc. benchmark function.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration"><a class="header" href="#configuration">Configuration</a></h1>
<p>Library benchmarks can be configured with the <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a> and
with <a href="benchmarks/library_benchmarks/../../cli_and_env/basics.html">Command-line arguments and Environment
variables</a>.</p>
<p>The <code>LibraryBenchmarkConfig</code> can be specified at different levels and sets the
configuration values for the same and lower levels. The values of the
<code>LibraryBenchmarkConfig</code> at higher levels can be overridden at a lower level.
Note that some values are additive rather than substitutive. Please see the docs
of the respective functions in <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.LibraryBenchmarkConfig.html"><code>LibraryBenchmarkConfig</code></a> for more details.</p>
<p>The different levels where a <code>LibraryBenchmarkConfig</code> can be specified.</p>
<ul>
<li>At top-level with the <code>main!</code> macro</li>
</ul>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">use iai_callgrind::{library_benchmark, library_benchmark_group};
</span>use iai_callgrind::{main, LibraryBenchmarkConfig};

<span class="boring">#[library_benchmark] fn bench() {}
</span><span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench);
</span><span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default();
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<ul>
<li>At group-level in the <code>library_benchmark_group!</code> macro</li>
</ul>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">use iai_callgrind::library_benchmark;
</span>use iai_callgrind::{main, LibraryBenchmarkConfig, library_benchmark_group};

<span class="boring">#[library_benchmark] fn bench() {}
</span>library_benchmark_group!(
    name = my_group;
    config = LibraryBenchmarkConfig::default();
    benchmarks = bench
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<ul>
<li>At <code>#[library_benchmark]</code> level</li>
</ul>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{
    main, LibraryBenchmarkConfig, library_benchmark_group, library_benchmark
};
use std::hint::black_box;

#[library_benchmark(config = LibraryBenchmarkConfig::default())] 
fn bench() {
    /* ... */
}

library_benchmark_group!(
    name = my_group;
    config = LibraryBenchmarkConfig::default();
    benchmarks = bench
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<ul>
<li>and at <code>#[bench]</code>, <code>#[benches]</code> level</li>
</ul>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{
    main, LibraryBenchmarkConfig, library_benchmark_group, library_benchmark
};
use std::hint::black_box;

#[library_benchmark] 
#[bench::some_id(args = (1, 2), config = LibraryBenchmarkConfig::default())]
#[benches::multiple(
    args = [(3, 4), (5, 6)], 
    config = LibraryBenchmarkConfig::default()
)]
fn bench(a: u8, b: u8) {
    /* ... */
<span class="boring">    _ = (a, b);
</span>}

library_benchmark_group!(
    name = my_group;
    config = LibraryBenchmarkConfig::default();
    benchmarks = bench
);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="custom-entry-points"><a class="header" href="#custom-entry-points">Custom entry points</a></h1>
<p>The <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/enum.EntryPoint.html"><code>EntryPoint</code></a> can be set to <code>EntryPoint::None</code> which disables
the entry point, <code>EntryPoint::Default</code> which uses the benchmark function as
entry point or <code>EntryPoint::Custom</code> which will be discussed in more detail in
this chapter.</p>
<p>To understand custom entry points let's take a small detour into how
<a href="https://valgrind.org/docs/manual/cl-manual.html"><code>Callgrind</code></a> and Iai-Callgrind work under the hood.</p>
<h2 id="iai-callgrind-under-the-hood"><a class="header" href="#iai-callgrind-under-the-hood">Iai-Callgrind under the hood</a></h2>
<p><code>Callgrind</code> collects metrics and associates them with a function. This happens
based on the compiled code not the source code, so it is possible to hook into
any function not only public functions. <code>Callgrind</code> can be configured to switch
instrumentation on and off based on a function name with
<a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.options"><code>--toggle-collect</code></a>. Per default, Iai-Callgrind sets this
toggle (which we call <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/enum.EntryPoint.html"><code>EntryPoint</code></a>) to the benchmarking function. Setting the
toggle implies <code>--collect-atstart=no</code>. So, all events before (in the <code>setup</code>)
and after the benchmark function (in the <code>teardown</code>) are not collected. Somewhat
simplified, but conveying the basic idea, here is a commented example:</p>
<pre><pre class="playground"><code class="language-rust edition2021">// &lt;-- collect-at-start=no

<span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{main,library_benchmark_group, library_benchmark};
use std::hint::black_box;

#[library_benchmark]
fn bench() -&gt; Vec&lt;i32&gt; { // &lt;-- DEFAULT ENTRY POINT starts collecting events
    black_box(my_lib::bubble_sort(vec![3, 2, 1]))
} // &lt;-- stop collecting events

library_benchmark_group!( name = my_group; benchmarks = bench);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<h3 id="pitfall-inlined-functions"><a class="header" href="#pitfall-inlined-functions">Pitfall: Inlined functions</a></h3>
<p>The fact that <code>Callgrind</code> acts on the compiled code harbors a pitfall. The
compiler with compile-time optimizations switched on (which is usually the case
when compiling benchmarks) inlines functions if it sees an advantage in doing
so. Iai-Callgrind takes care, that this doesn't happen with the benchmark
function, so <code>Callgrind</code> can find and hook into the benchmark function. But, in
your production code you actually don't want to stop the compiler from doing
its job just to be able to benchmark that function. So, be cautious with
benchmarking private functions and only choose functions of which it is known
that they are not being inlined.</p>
<h2 id="hook-into-private-functions"><a class="header" href="#hook-into-private-functions">Hook into private functions</a></h2>
<p>The basic idea is to choose a public function in your library acting as access
point to the actual function you want to benchmark. As outlined before, this
works only reliably for functions which are not inlined by the compiler.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    EntryPoint
};
use std::hint::black_box;

mod my_lib {
     #[inline(never)]
     fn bubble_sort(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         // The algorithm
<span class="boring">       input
</span>     }

     pub fn access_point(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         println!("Doing something before the function call");
         bubble_sort(input)
     }
}

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .entry_point(EntryPoint::Custom("*::my_lib::bubble_sort".to_owned()))
)]
#[bench::small(vec![3, 2, 1])]
#[bench::bigger(vec![5, 4, 3, 2, 1])]
fn bench_private(array: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::access_point(array))
}

library_benchmark_group!(name = my_group; benchmarks = bench_private);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Note the <code>#[inline(never)]</code> we use in this example to make sure the
<code>bubble_sort</code> function is not getting inlined.</p>
<p>We use a <a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.options">wildcard</a> <code>*::my_lib::bubble_sort</code> for
<code>EntryPoint::Custom</code> for demonstration purposes. You might want to tighten this
pattern. If you don't know how the pattern looks like, use <code>EntryPoint::None</code>
first then run the benchmark. Now, investigate the <a href="benchmarks/library_benchmarks/../../cli_and_env/output/out_directory.html">callgrind output
file</a>. This output file is pretty
low-level but all you need to do is search for the entries which start with
<code>fn=...</code>. In the example above this entry might look like
<code>fn=algorithms::my_lib::bubble_sort</code> if <code>my_lib</code> would be part of the top-level
<code>algorithms</code> module. Or, using grep:</p>
<pre><code class="language-shell">grep '^fn=.*::bubble_sort$' target/iai/the_package/benchmark_file_name/my_group/bench_private.bigger/callgrind.bench_private.bigger.out
</code></pre>
<p>Having found the pattern, you can eventually use <code>EntryPoint::Custom</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD025 MD042 MD033 -->
<h1 id="multi-threaded-and-multi-process-applications"><a class="header" href="#multi-threaded-and-multi-process-applications">Multi-threaded and multi-process applications</a></h1>
<p>The default is to run Iai-Callgrind benchmarks with <code>--separate-threads=yes</code>,
<code>--trace-children=yes</code> switched on. This enables Iai-Callgrind to trace threads
and subprocesses, respectively. Note that <code>--separate-threads=yes</code> is not
strictly necessary to be able to trace threads. But, if they are separated,
Iai-Callgrind can collect and display the metrics for each thread. Due to the
way <code>callgrind</code> applies <a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.options.collection">data collection options</a> like <code>--toggle-collect</code>,
<code>--collect-atstart</code>, ... further configuration is needed in library benchmarks.</p>
<p>To actually see the collected metrics in the terminal output for all threads
and/or subprocesses you can switch on <code>OutputFormat::show_intermediate</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn find_primes_multi_thread(_: u64) -&gt; Vec&lt;u64&gt; { vec![]} }
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    OutputFormat
};
use std::hint::black_box;

#[library_benchmark]
fn bench_threads() -&gt; Vec&lt;u64&gt; {
    black_box(my_lib::find_primes_multi_thread(2))
}

library_benchmark_group!(name = my_group; benchmarks = bench_threads);
<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .output_format(OutputFormat::default()
            .show_intermediate(true)
        );
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>The best method for benchmarking threads and subprocesses depends heavily on
your code. So, rather than suggesting a single "best" method for benchmarking
threads and subprocesses, this chapter will run through various possible
approaches and try to highlight the pros and cons of each.</p>
<h2 id="multi-threaded-applications"><a class="header" href="#multi-threaded-applications">Multi-threaded applications</a></h2>
<p><code>Callgrind</code> treats each thread and process as a separate unit and it applies
data collection options to each unit. In library benchmarks the <a href="benchmarks/library_benchmarks/./custom_entry_point.html">entry
point</a> (or the default toggle) for <code>callgrind</code> is per
default set to the benchmark function with the help of the <code>--toggle-collect</code>
option. Setting <code>--toggle-collect</code> also automatically sets
<code>--collect-atstart=no</code>. If not further customized for a benchmarked
multi-threaded function, these options cause the metrics for the spawned threads
to be zero. This happens since each thread is a separate unit with
<code>--collect-atstart=no</code> and the default toggle applied to the units. The default
toggle is set to the benchmark function and does not hook into any function in
the thread, so the metrics are zero.</p>
<p>There are multiple ways to customize the default behaviour and actually measure
the threads. For the following examples, we're using the benchmark and library
code below to show the different customization options assuming this code lives
in a benchmark file <code>benches/lib_bench_threads.rs</code></p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    OutputFormat
};
use std::hint::black_box;

/// Suppose this is your library
pub mod my_lib {
    /// Return true if `num` is a prime number
    pub fn is_prime(num: u64) -&gt; bool {
        if num &lt;= 1 {
            return false;
        }

        for i in 2..=(num as f64).sqrt() as u64 {
            if num % i == 0 {
                return false;
            }
        }

        true
    }

    /// Find and return all prime numbers in the inclusive range `low` to `high`
    pub fn find_primes(low: u64, high: u64) -&gt; Vec&lt;u64&gt; {
        (low..=high).filter(|n| is_prime(*n)).collect()
    }

    /// Return the prime numbers in the range `0..(num_threads * 10000)`
    pub fn find_primes_multi_thread(num_threads: usize) -&gt; Vec&lt;u64&gt; {
        let mut handles = vec![];
        let mut low = 0;
        for _ in 0..num_threads {
            let handle = std::thread::spawn(move || find_primes(low, low + 10000));
            handles.push(handle);

            low += 10000;
        }

        let mut primes = vec![];
        for handle in handles {
            let result = handle.join();
            primes.extend(result.unwrap())
        }

        primes
    }
}

#[library_benchmark]
#[bench::two_threads(2)]
fn bench_threads(num_threads: usize) -&gt; Vec&lt;u64&gt; {
    black_box(my_lib::find_primes_multi_thread(num_threads))
}

library_benchmark_group!(name = my_group; benchmarks = bench_threads);
<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .output_format(OutputFormat::default()
            .show_intermediate(true)
        );
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>Running this benchmark with <code>cargo bench</code> will present you with the following
terminal output:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2097219 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                       <b>27305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66353</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>341</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>539</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67233</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86923</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2097219 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2097219 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                       <b>27305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66353</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>341</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>539</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67233</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86923</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>As you can see, the counts for the threads <code>2</code> and <code>3</code> (our spawned threads) are
all zero.</p>
<h3 id="measuring-threads-using-toggles"><a class="header" href="#measuring-threads-using-toggles">Measuring threads using toggles</a></h3>
<p>At a first glance, setting a toggle to the function in the thread seems to be
easiest way and can be done like so:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn find_primes_multi_thread(_: usize) -&gt; Vec&lt;u64&gt; { vec![] }}
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    EntryPoint
};
use std::hint::black_box;

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .callgrind_args(["--toggle-collect=lib_bench_threads::my_lib::find_primes"])
)]
#[bench::two_threads(2)]
fn bench_threads(num_threads: usize) -&gt; Vec&lt;u64&gt; {
    black_box(my_lib::find_primes_multi_thread(num_threads))
}
<span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench_threads);
</span><span class="boring">fn main() {
</span><span class="boring">main!(library_benchmark_groups = my_group);
</span><span class="boring">}</span></code></pre></pre>
<p>This approach may or may not work, depending on whether the compiler inlines the
target function of the <code>--toggle-collect</code> argument or not. This is the same
problem as with <a href="benchmarks/library_benchmarks/./custom_entry_point.html#pitfall-inlined-functions">custom entry
points</a>. As can be seen
below, the compiler has chosen to inline <code>find_primes</code> and the metrics for the
threads are still zero:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2620776 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                       <b>27372</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66431</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>343</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>538</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67312</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86976</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2620776 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2620776 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                       <b>27372</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66431</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>343</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>538</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67312</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86976</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>Just to show what would happen if the compiler does not inline the <code>find_primes</code>
method, we temporarily annotate it with <code>#[inline(never)]</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Find and return all prime numbers in the inclusive range `low` to `high`
<span class="boring">fn is_prime(_: u64) -&gt; bool { true }
</span>#[inline(never)]
pub fn find_primes(low: u64, high: u64) -&gt; Vec&lt;u64&gt; {
    (low..=high).filter(|n| is_prime(*n)).collect()
}
<span class="boring">}</span></code></pre></pre>
<p>Now, running the benchmark does show the desired metrics:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2661917 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                       <b>27372</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66431</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>343</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>538</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67312</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86976</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2661917 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>2460503</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>2534938</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>12</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>186</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>2535136</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>2541508</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2661917 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>3650410</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>3724286</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>4</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>130</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>3724420</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>3728856</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                     <b>6138285</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>6325655</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>359</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>854</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>6326868</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>6357340</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>But, annotating functions with <code>#[inline(never)]</code> in production code is usually
not an option and preventing the compiler from doing its job is not the
preferred way to make a benchmark work. The truth is, there is no way to make
the <code>--toggle-collect</code> argument work for all cases and it heavily depends on the
choices of the compiler depending on your code.</p>
<p>Another way to get the thread metrics is to set <code>--collect-atstart=yes</code> and turn
off the <code>EntryPoint</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn find_primes_multi_thread(_: usize) -&gt; Vec&lt;u64&gt; { vec![] }}
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    EntryPoint
};
use std::hint::black_box;

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .entry_point(EntryPoint::None)
        .callgrind_args(["--collect-atstart=yes"])
)]
#[bench::two_threads(2)]
fn bench_threads(num_threads: usize) -&gt; Vec&lt;u64&gt; {
    black_box(my_lib::find_primes_multi_thread(num_threads))
}
<span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench_threads);
</span><span class="boring">fn main() {
</span><span class="boring">main!(library_benchmark_groups = my_group);
</span><span class="boring">}</span></code></pre></pre>
<p>But, the metrics of the main thread will include all the setup (and teardown)
code from the benchmark executable (so the instructions of the main thread go up
from <code>27372</code> to <code>404425</code>):</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2697019 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                      <b>404425</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                           <b>570186</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                             <b>1307</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                            <b>4856</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                  <b>576349</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                  <b>746681</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2697019 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>2466864</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>2543314</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>81</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>409</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>2543804</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>2558034</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2697019 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>3656729</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>3732802</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>31</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>201</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>3733034</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>3739992</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                     <b>6528018</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>6846302</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                             <b>1419</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                            <b>5466</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>6853187</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>7044707</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>Additionally, expect a lot of metric changes if the benchmarks itself are
changed. However, if the metrics of the main thread are not significant compared
to the total, this might be an applicable (last) choice.</p>
<p>There is another more reliable way as shown below in the next section.</p>
<h3 id="measuring-threads-using-client-requests"><a class="header" href="#measuring-threads-using-client-requests">Measuring threads using client requests</a></h3>
<p>The perhaps most reliable and flexible way to measure threads is using <a href="benchmarks/library_benchmarks/../../client_requests.html">client
requests</a>. The downside is that you have to put some
benchmark code into your production code. But, if you followed the installation
instructions in <a href="benchmarks/library_benchmarks/../../client_requests.html">client requests</a>, this additional
code is only compiled in benchmarks, not in your final production-ready library.</p>
<p>Using the callgrind client request, we adjust the threads in the
<code>find_primes_multi_thread</code> function like so:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">fn find_primes(_a: u64, _b: u64) -&gt; Vec&lt;u64&gt; { vec![] }
</span><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::client_requests::callgrind;

/// Return the prime numbers in the range `0..(num_threads * 10000)`
pub fn find_primes_multi_thread(num_threads: usize) -&gt; Vec&lt;u64&gt; {
    let mut handles = vec![];
    let mut low = 0;
    for _ in 0..num_threads {
        let handle = std::thread::spawn(move || {
            callgrind::toggle_collect();
            let result = find_primes(low, low + 10000);
            callgrind::toggle_collect();
            result
        });
        handles.push(handle);

        low += 10000;
    }

    let mut primes = vec![];
    for handle in handles {
        let result = handle.join();
        primes.extend(result.unwrap())
    }

    primes
}
<span class="boring">}</span></code></pre></pre>
<p>and running the same benchmark now will show the collected metrics of the
threads:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2149242 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                       <b>27305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>66352</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>344</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>537</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>67233</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>86867</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2149242 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>2460501</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>2534935</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>13</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>185</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>2535133</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>2541475</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2149242 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>3650408</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>3724285</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>1</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>131</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>3724417</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>3728875</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                     <b>6138214</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>6325572</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                              <b>358</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>853</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>6326783</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>6357217</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>Using the client request toggles is very flexible since you can put the
<code>iai_callgrind::client_requests::callgrind::toggle_collect</code> instructions
anywhere in the threads. In this example, we just have a single function in the
thread, but if your threads consist of more than just a single function, you can
easily exclude uninteresting parts from the final measurements.</p>
<p>If you want to prevent the code of the main thread from being measured, you can
use the following:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn find_primes_multi_thread(_: usize) -&gt; Vec&lt;u64&gt; { vec![] }}
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    EntryPoint
};
use std::hint::black_box;

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .entry_point(EntryPoint::None)
        .callgrind_args(["--collect-atstart=no"])
)]
#[bench::two_threads(2)]
fn bench_threads(num_threads: usize) -&gt; Vec&lt;u64&gt; {
    black_box(my_lib::find_primes_multi_thread(num_threads))
}
<span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench_threads);
</span><span class="boring">fn main() {
</span><span class="boring">main!(library_benchmark_groups = my_group);
</span><span class="boring">}</span></code></pre></pre>
<p>Setting the <code>EntryPoint::None</code> disables the default toggle but also
<code>--collect-atstart=no</code>, which is why we have to set the option manually.
Altogether, running the benchmark will show:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_threads::my_group::bench_threads</span> <span style="color:#0AA">two_threads</span><span style="color:#0AA">:</span><b><span style="color:#00A">2</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2251257 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2251257 thread: 2 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>2460501</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>2534935</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>11</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>187</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>2535133</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>2541535</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 2251257 thread: 3 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_threads-b85159a94ccb3851</span></b>
<span style="color:#555">  </span>Instructions:                     <b>3650408</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>3724282</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>4</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>131</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>3724417</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>3728887</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                     <b>6110909</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                          <b>6259217</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>15</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>318</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                 <b>6259550</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                 <b>6270422</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<h2 id="multi-process-applications"><a class="header" href="#multi-process-applications">Multi-process applications</a></h2>
<p>Measuring multi-process applications is in principal not that different from
multi-threaded applications since subprocesses are just like threads separate
units. As for threads, the <a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.options.collection">data collection options</a> are applied to subprocesses
separately from the main process.</p>
<p>Note there are multiple <a href="https://valgrind.org/docs/manual/manual-core.html#manual-core.basicopts">valgrind command-line
arguments</a>
that can disable the collection of metrics for uninteresting subprocesses, for
example subprocesses that are spawned by your library function but are not part
of your library/binary crate.</p>
<p>For the following examples suppose the code below is the <code>cat</code> binary and part
of a crate (so we can use
<a href="https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-crates"><code>env!("CARGO_BIN_EXE_cat")</code></a>):</p>
<pre><pre class="playground"><code class="language-rust edition2021">use std::fs::File;
use std::io::{copy, stdout, BufReader, BufWriter, Write};

<span class="boring">fn main() {
</span>fn main() {
    let mut args_iter = std::env::args().skip(1);
    let file_arg = args_iter.next().expect("File argument should be present");

    let file = File::open(file_arg).expect("Opening file should succeed");
    let stdout = stdout().lock();

    let mut writer = BufWriter::new(stdout);
    copy(&amp;mut BufReader::new(file), &amp;mut writer)
        .expect("Printing file to stdout should succeed");

    writer.flush().expect("Flushing writer should succeed");
}
<span class="boring">}</span></code></pre></pre>
<p>The above binary is a very simple version of <code>cat</code> taking a single file
argument. The file content is read and dumped to the <code>stdout</code>. The following is
the benchmark and library code to show the different options assuming this code
is stored in a benchmark file <code>benches/lib_bench_subprocess.rs</code></p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use std::hint::black_box;
use std::io;
use std::path::PathBuf;
use std::process::ExitStatus;

use iai_callgrind::{
    library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
    OutputFormat,
};

/// Suppose this is your library
pub mod my_lib {
    use std::io;
    use std::path::Path;
    use std::process::ExitStatus;

    /// A function executing the crate's binary `cat`
    pub fn cat(file: &amp;Path) -&gt; io::Result&lt;ExitStatus&gt; {
        std::process::Command::new(env!("CARGO_BIN_EXE_cat"))
            .arg(file)
            .status()
    }
}

/// Create a file `/tmp/foo.txt` with some content
fn create_file() -&gt; PathBuf {
    let path = PathBuf::from("/tmp/foo.txt");
    std::fs::write(&amp;path, "some content").unwrap();
    path
}

#[library_benchmark]
#[bench::some(setup = create_file)]
fn bench_subprocess(path: PathBuf) -&gt; io::Result&lt;ExitStatus&gt; {
    black_box(my_lib::cat(&amp;path))
}

library_benchmark_group!(name = my_group; benchmarks = bench_subprocess);
<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .output_format(OutputFormat::default()
            .show_intermediate(true)
        );
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>Running the above benchmark with <code>cargo bench</code> results in the following terminal
output:</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_subprocess::my_group::bench_subprocess</span> <span style="color:#0AA">some</span><span style="color:#0AA">:</span><b><span style="color:#00A">create_file()</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3141785 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_subprocess-a1b2e1eac5125819</span></b>
<span style="color:#555">  </span>Instructions:                        <b>4467</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>6102</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>17</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>186</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>6305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>12697</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3141786 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/cat /tmp/foo.txt</span></b>
<span style="color:#555">  </span>Instructions:                           <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                               <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                       <b>0</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                        <b>4467</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>6102</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>17</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>186</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>6305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>12697</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>As expected, the <code>cat</code> subprocess is not measured and the metrics are zero for
the same reasons as the initial measurement of threads.</p>
<h3 id="measuring-subprocesses-using-toggles"><a class="header" href="#measuring-subprocesses-using-toggles">Measuring subprocesses using toggles</a></h3>
<p>The great advantage over measuring threads is that each process has a main
function that is not inlined by the compiler and can serve as a reliable hook
for the <code>--toggle-collect</code> argument so the following adaption to the above
benchmark will just work:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib {
</span><span class="boring">use std::{io, path::Path, process::ExitStatus};
</span><span class="boring">pub fn cat(_: &amp;Path) -&gt; io::Result&lt;ExitStatus&gt; {
</span><span class="boring">   std::process::Command::new("some").status()
</span><span class="boring">}}
</span><span class="boring">fn create_file() -&gt; PathBuf { PathBuf::from("some") }
</span><span class="boring">use std::hint::black_box;
</span><span class="boring">use std::io;
</span><span class="boring">use std::path::PathBuf;
</span><span class="boring">use std::process::ExitStatus;
</span><span class="boring">use iai_callgrind::{
</span><span class="boring">   library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
</span><span class="boring">   OutputFormat,
</span><span class="boring">};
</span>#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .callgrind_args(["--toggle-collect=cat::main"])
)]
#[bench::some(setup = create_file)]
fn bench_subprocess(path: PathBuf) -&gt; io::Result&lt;ExitStatus&gt; {
    black_box(my_lib::cat(&amp;path))
}
<span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench_subprocess);
</span><span class="boring">fn main() {
</span><span class="boring">main!(library_benchmark_groups = my_group);
</span><span class="boring">}</span></code></pre></pre>
<p>producing the desired output</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_subprocess::my_group::bench_subprocess</span> <span style="color:#0AA">some</span><span style="color:#0AA">:</span><b><span style="color:#00A">create_file()</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3324117 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_subprocess-a1b2e1eac5125819</span></b>
<span style="color:#555">  </span>Instructions:                        <b>4475</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>6112</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>14</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>187</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>6313</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>12727</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3324119 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/cat /tmp/foo.txt</span></b>
<span style="color:#555">  </span>Instructions:                        <b>4019</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>5575</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>12</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>167</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>5754</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>11480</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                        <b>8494</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                            <b>11687</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>26</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>354</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                   <b>12067</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>24207</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<h3 id="measuring-subprocesses-using-client-requests"><a class="header" href="#measuring-subprocesses-using-client-requests">Measuring subprocesses using client requests</a></h3>
<p>Naturally, client requests can also be used to measure subprocesses. The
callgrind client requests are added to the code of the <code>cat</code> binary:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use std::fs::File;
use std::io::{copy, stdout, BufReader, BufWriter, Write};
use iai_callgrind::client_requests::callgrind;

<span class="boring">fn main() {
</span>fn main() {
    let mut args_iter = std::env::args().skip(1);
    let file_arg = args_iter.next().expect("File argument should be present");

    callgrind::toggle_collect();
    let file = File::open(file_arg).expect("Opening file should succeed");
    let stdout = stdout().lock();

    let mut writer = BufWriter::new(stdout);
    copy(&amp;mut BufReader::new(file), &amp;mut writer)
        .expect("Printing file to stdout should succeed");

    writer.flush().expect("Flushing writer should succeed");
    callgrind::toggle_collect();
}
<span class="boring">}</span></code></pre></pre>
<p>For the purpose of this example we decided that measuring the parsing of the
command-line-arguments is not interesting for us and excluded it from the
collected metrics. The benchmark itself is reverted to its original state
without the toggle:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib {
</span><span class="boring">use std::{io, path::Path, process::ExitStatus};
</span><span class="boring">pub fn cat(_: &amp;Path) -&gt; io::Result&lt;ExitStatus&gt; {
</span><span class="boring">   std::process::Command::new("some").status()
</span><span class="boring">}}
</span><span class="boring">fn create_file() -&gt; PathBuf { PathBuf::from("some") }
</span><span class="boring">use std::hint::black_box;
</span><span class="boring">use std::io;
</span><span class="boring">use std::path::PathBuf;
</span><span class="boring">use std::process::ExitStatus;
</span><span class="boring">use iai_callgrind::{
</span><span class="boring">   library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
</span><span class="boring">   OutputFormat,
</span><span class="boring">};
</span>#[library_benchmark]
#[bench::some(setup = create_file)]
fn bench_subprocess(path: PathBuf) -&gt; io::Result&lt;ExitStatus&gt; {
    black_box(my_lib::cat(&amp;path))
}
<span class="boring">library_benchmark_group!(name = my_group; benchmarks = bench_subprocess);
</span><span class="boring">fn main() {
</span><span class="boring">main!(library_benchmark_groups = my_group);
</span><span class="boring">}</span></code></pre></pre>
<p>Now, running the benchmark shows</p>
<pre><code class="hljs"><span style="color:#0A0">lib_bench_subprocess::my_group::bench_subprocess</span> <span style="color:#0AA">some</span><span style="color:#0AA">:</span><b><span style="color:#00A">create_file()</span></b>
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3421822 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/deps/lib_bench_subprocess-a1b2e1eac5125819</span></b>
<span style="color:#555">  </span>Instructions:                        <b>4467</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>6102</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>17</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>186</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>6305</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>12697</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>pid: 3421823 thread: 1 part: 1</b>        |N/A
<span style="color:#555">  </span>Command:             <b><span style="color:#00A">target/release/cat /tmp/foo.txt</span></b>
<span style="color:#555">  </span>Instructions:                        <b>2429</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>3406</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                                <b>8</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>138</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>3552</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                    <b>8276</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span><span style="color:#A50">##</span> <b>Total</b>
<span style="color:#555">  </span>Instructions:                        <b>6896</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L1 Hits:                             <b>9508</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>L2 Hits:                               <b>25</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>RAM Hits:                             <b>324</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Total read+write:                    <b>9857</b>|N/A                  (<span style="color:#555">*********</span>)
<span style="color:#555">  </span>Estimated Cycles:                   <b>20973</b>|N/A                  (<span style="color:#555">*********</span>)</code></pre>
<p>As expected, the metrics for the <code>cat</code> binary are a little bit lower since we
skipped measuring the parsing of the command-line arguments.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="even-more-examples"><a class="header" href="#even-more-examples">Even more Examples</a></h1>
<p>I'm referring here to the <a href="https://github.com/iai-callgrind/iai-callgrind">github
repository</a>. We test the library
benchmarks functionality of Iai-Callgrind with system tests in the private
<a href="https://github.com/iai-callgrind/iai-callgrind/tree/main/benchmark-tests/benches/test_lib_bench">benchmark-tests</a>
package.</p>
<p>Each system test there can serve you as an example, but for a fully documented
and commented one see
<a href="https://github.com/iai-callgrind/iai-callgrind/blob/main/benchmark-tests/benches/test_lib_bench/groups/test_lib_bench_groups.rs">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="binary-benchmarks"><a class="header" href="#binary-benchmarks">Binary Benchmarks</a></h1>
<p>You want to start benchmarking your crate's binary? Best start with the
<a href="benchmarks/./binary_benchmarks/quickstart.html">Quickstart</a> section.</p>
<p>Setting up binary benchmarks is very similar to library benchmarks, and it's a
good idea to have a look at the <a href="benchmarks/./library_benchmarks.html">library benchmark</a>
section of this guide, too.</p>
<p>You may then come back to the binary benchmarks section and go through the
<a href="benchmarks/./binary_benchmarks/differences.html">differences</a></p>
<p>If you need more examples see <a href="benchmarks/./binary_benchmarks/examples.html">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="important-default-behaviour-1"><a class="header" href="#important-default-behaviour-1">Important default behaviour</a></h1>
<p>As in library benchmarks, the environment variables are cleared before running a
binary benchmark. Have a look at the <a href="benchmarks/binary_benchmarks/./configuration.html">Configuration</a> section
if you want to change this behavior. Iai-Callgrind sometimes deviates from the
valgrind defaults which are:</p>
<div class="table-wrapper"><table><thead><tr><th>Iai-Callgrind</th><th>Valgrind (v3.23)</th></tr></thead><tbody>
<tr><td><code>--trace-children=yes</code></td><td><code>--trace-children=no</code></td></tr>
<tr><td><code>--fair-sched=try</code></td><td><code>--fair-sched=no</code></td></tr>
<tr><td><code>--separate-threads=yes</code></td><td><code>--separate-threads=no</code></td></tr>
<tr><td><code>--cache-sim=yes</code></td><td><code>--cache-sim=no</code></td></tr>
</tbody></table>
</div>
<p>As show in the table above, the benchmarks run with cache simulation switched
on. This adds run time for each benchmark. If you don't need the cache metrics
and estimation of cycles, you can easily switch cache simulation off for example
with</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::BinaryBenchmarkConfig;

BinaryBenchmarkConfig::default().callgrind_args(["--cache-sim=no"]);
<span class="boring">}</span></code></pre></pre>
<p>To switch off cache simulation for all benchmarks in the same file:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
    binary_benchmark, binary_benchmark_group, main, BinaryBenchmarkConfig
};

#[binary_benchmark]
fn bench_binary() -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(
    config = BinaryBenchmarkConfig::default().callgrind_args(["--cache-sim=no"]);
    binary_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="quickstart-1"><a class="header" href="#quickstart-1">Quickstart</a></h1>
<p>Suppose the crate's binary is called <code>my-foo</code> and this binary takes a file path
as positional argument. This first example shows the basic usage of the
high-level api with the <code>#[binary_benchmark]</code> attribute:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{binary_benchmark, binary_benchmark_group, main};

#[binary_benchmark]
#[bench::some_id("foo.txt")]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(
    name = my_group;
    benchmarks = bench_binary
);

<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>If you want to try out this example with your crate's binary, put the above code
into a file in <code>$WORKSPACE_ROOT/benches/binary_benchmark.rs</code>. Next, replace
<code>my-foo</code> in <code>env!("CARGO_BIN_EXE_my-foo")</code> with the name of a binary of your
crate.</p>
<p>Note the <code>env!</code> macro is a <a href="https://doc.rust-lang.org/std/macro.env.html">rust</a>
builtin macro and <code>CARGO_BIN_EXE_&lt;name&gt;</code> is documented
<a href="https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-crates">here</a>.</p>
<p>You should always use <code>env!("CARGO_BIN_EXE_&lt;name&gt;")</code> to determine the path to
the binary of your crate. Do not use relative paths like <code>target/release/my-foo</code>
since this might break your benchmarks in many ways. The environment variable
does exactly the right thing and the usage is short and simple.</p>
<p>Lastly, adjust the argument of the <code>Command</code> and add the following to your
<code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[[bench]]
name = "binary_benchmark"
harness = false
</code></pre>
<p>Running</p>
<pre><code class="language-shell">cargo bench
</code></pre>
<p>presents you with something like the following:</p>
<pre><code class="hljs"><span style="color:#0A0">binary_benchmark::my_group::bench_binary</span> <span style="color:#0AA">some_id</span><span style="color:#0AA">:</span><b><span style="color:#00A">("foo.txt") -> target/release/my-foo foo.txt</span></b>
  Instructions:     <b>         342129</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>         457370</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>            734</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>           4096</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>         462200</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>         604400</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>As opposed to library benchmarks, binary benchmarks have access to a <a href="benchmarks/binary_benchmarks/./low_level.html">low-level
api</a>. Here, pretty much the same as the above high-level usage
but written in the low-level api:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{BinaryBenchmark, Bench, binary_benchmark_group, main};

binary_benchmark_group!(
    name = my_group;
    benchmarks = |group: &amp;mut BinaryBenchmarkGroup| {
        group.binary_benchmark(BinaryBenchmark::new("bench_binary")
            .bench(Bench::new("some_id")
                .command(iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
                    .arg("foo.txt")
                    .build()
                )
            )
        )
    }
);

<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>If in doubt, use the high-level api. You can still
<a href="benchmarks/binary_benchmarks/./low_level.html#intermixing-high-level-and-low-level-api">migrate</a> to the
low-level api very easily if you really need to. The other way around is more
involved.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="differences-to-library-benchmarks"><a class="header" href="#differences-to-library-benchmarks">Differences to library benchmarks</a></h1>
<p>In this section we're going through the differences to <a href="benchmarks/binary_benchmarks/../library_benchmarks.html">library
benchmarks</a>. This assumes that you already know how to
set up library benchmarks, and it is recommended to learn the very basics about
library benchmarks, starting with
<a href="benchmarks/binary_benchmarks/../binary_benchmarks/quickstart.html">Quickstart</a>, <a href="benchmarks/binary_benchmarks/../library_benchmarks/anatomy.html">Anatomy of a library
benchmark</a> and <a href="benchmarks/binary_benchmarks/../library_benchmarks/macros.html">The macros in more
detail</a>. Then come back to this section.</p>
<h2 id="name-changes"><a class="header" href="#name-changes">Name changes</a></h2>
<p>Coming from library benchmarks, the names with <code>library</code> in it change to the
same name but <code>library</code> with <code>binary</code> replaced, so the <code>#[library_benchmark]</code>
attribute's name changes to <code>#[binary_benchmark]</code> and <code>library_benchmark_group!</code>
changes to <code>binary_benchmark_group!</code>, the config arguments take a
<code>BinaryBenchmarkConfig</code> instead of a <code>LibraryBenchmarkConfig</code>...</p>
<p>A quick reference of available macros in binary benchmarks:</p>
<ul>
<li><code>#[binary_benchmark]</code> and its inner attributes <code>#[bench]</code> and <code>#[benches]</code>:
The exact pendant to the <code>#[library_benchmark]</code> attribute macro.</li>
<li><code>binary_benchmark_group!</code>: Just the name of the macro has changed.</li>
<li><code>binary_benchmark_attribute!</code>: An additional macro if you intend to
<a href="benchmarks/binary_benchmarks/./low_level.html#intermixing-high-level-and-low-level-api">migrate</a> from the high-level to the low-level
api</li>
<li><code>main!</code>: The same macro as in library benchmarks but the name of the
<code>library_benchmark_groups</code> parameter changed to <code>binary_benchmark_groups</code>.</li>
</ul>
<p>To see all macros in action have a look at the example below.</p>
<h2 id="the-return-value-of-the-benchmark-function"><a class="header" href="#the-return-value-of-the-benchmark-function">The return value of the benchmark function</a></h2>
<p>The maybe most important difference is, that the <code>#[binary_benchmark]</code> annotated
function always needs to return an <code>iai_callgrind::Command</code>. Note this function
builds the command which is going to be benchmarked but doesn't execute it,
yet. So, the code in this function does not attribute to the event counts of the
actual benchmark.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{binary_benchmark, binary_benchmark_group, main};
use std::path::PathBuf;

#[binary_benchmark]
#[bench::foo("foo.txt")]
#[bench::bar("bar.json")]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    // We can put any code in this function which is needed to configure and
    // build the `Command`.
    let path = PathBuf::from(path);

    // Here, if the `path` ends with `.txt` we want to see
    // the `Stdout` output of the `Command` in the benchmark output. In all other 
    // cases, the `Stdout` of the `Command` is redirected to a `File` with the
    // same name as the input `path` but with the extension `out`.
    let stdout = if path.extension().unwrap() == "txt" {
        iai_callgrind::Stdio::Inherit
    } else {
        iai_callgrind::Stdio::File(path.with_extension("out"))
    };
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .stdout(stdout)
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<h2 id="setup-and-teardown-1"><a class="header" href="#setup-and-teardown-1"><code>setup</code> and <code>teardown</code></a></h2>
<p>Since we can put any code building the <code>Command</code> in the function itself, the
<code>setup</code> and <code>teardown</code> of <code>#[binary_benchmark]</code>, <code>#[bench]</code> and <code>#[benches]</code>
work differently.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{binary_benchmark, binary_benchmark_group, main};

fn create_file() {
    std::fs::write("foo.txt", "some content").unwrap();
}

#[binary_benchmark]
#[bench::foo(args = ("foo.txt"), setup = create_file())]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p><code>setup</code>, which is here the expression <code>create_file()</code>, is not evaluated right
away and the return value of <code>setup</code> is not used as input for the <code>function</code>!
Instead, the expression in <code>setup</code> is getting evaluated and executed just before
the benchmarked <code>Command</code> is <strong>executed</strong>. Similarly, <code>teardown</code> is executed
after the <code>Command</code> is <strong>executed</strong>.</p>
<p>In the example above, <code>setup</code> creates always the same file and is pretty static.
It's possible to use the same arguments for <code>setup</code> (<code>teardown</code>) <strong>and</strong> the
<code>function</code> using the path (or file pointer) to a function as you're used to from
library benchmarks:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{binary_benchmark, binary_benchmark_group, main};

fn create_file(path: &amp;str) {
    std::fs::write(path, "some content").unwrap();
}

fn delete_file(path: &amp;str) {
    std::fs::remove_file(path).unwrap();
}

#[binary_benchmark]
// Note the missing parentheses for `setup` of the function `create_file` which
// tells Iai-Callgrind to pass the `args` to the `setup` function AND the
// function `bench_binary`
#[bench::foo(args = ("foo.txt"), setup = create_file)]
// Same for `teardown`
#[bench::bar(args = ("bar.txt"), setup = create_file, teardown = delete_file)]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-commands-stdin-and-simulating-piped-input"><a class="header" href="#the-commands-stdin-and-simulating-piped-input">The Command's stdin and simulating piped input</a></h1>
<p>The behaviour of <code>Stdin</code> of the <code>Command</code> can be changed, almost the same way as
the <code>Stdin</code> of a <code>std::process::Command</code> with the only difference, that we use
the enums <code>iai_callgrind::Stdin</code> and <code>iai_callgrind::Stdio</code>. These enums provide
the variants <code>Inherit</code> (the equivalent of <code>std::process::Stdio::inherit</code>),
<code>Pipe</code> (the equivalent of <code>std::process::Stdio::piped</code>) and so on. There's also
<code>File</code> which takes a <code>PathBuf</code> to the file which is used as <code>Stdin</code> for the
<code>Command</code>. This corresponds to a redirection in the shell as in <code>my-foo &lt; path/to/file</code>.</p>
<p>Moreover, <code>iai_callgrind::Stdin</code> provides the <code>Stdin::Setup</code> variant specific to
Iai-Callgrind:</p>
<p>Applications may change their behaviour if the input or the <code>Stdin</code> of the
<code>Command</code> is coming from a pipe as in <code>echo "some content" | my-foo</code>. To be able
to benchmark such cases, it is possible to use the output of <code>setup</code> to <code>Stdout</code>
or <code>Stderr</code> as <code>Stdin</code> for the <code>Command</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{binary_benchmark, binary_benchmark_group, main, Stdin, Pipe};

fn setup_pipe() {
    println!(
        "The output to `Stdout` here will be the input or `Stdin` of the `Command`"
    );
}

#[binary_benchmark]
#[bench::foo(setup = setup_pipe())]
fn bench_binary() -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .stdin(Stdin::Setup(Pipe::Stdout))
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Usually, <code>setup</code> then the <code>Command</code> and then <code>teardown</code> are executed
sequentially, each waiting for the previous process to exit successfully (See
also <a href="benchmarks/binary_benchmarks/./configuration/exit_code.html">Configure the exit code of the Command</a>). If
the <code>Command::stdin</code> changes to <code>Stdin::Setup</code>, <code>setup</code> and the <code>Command</code> are
executed in parallel and Iai-Callgrind waits first for the <code>Command</code> to exit,
then <code>setup</code>. After the successful exit of <code>setup</code>, <code>teardown</code> is executed.</p>
<p>Since <code>setup</code> and <code>Command</code> are run in parallel if <code>Stdin::Setup</code> is used, it is
sometimes necessary to delay the execution of the <code>Command</code>. Please see the
<a href="benchmarks/binary_benchmarks/./configuration/delay.html"><code>delay</code></a> chapter for more details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-1"><a class="header" href="#configuration-1">Configuration</a></h1>
<p>The configuration of binary benchmarks works the same way as in library
benchmarks with the name changing from <code>LibraryBenchmarkConfig</code> to
<code>BinaryBenchmarkConfig</code>. Please see
<a href="benchmarks/binary_benchmarks/../library_benchmarks/configuration.html">there</a> for the basics. However, Binary
benchmarks have some additional configuration possibilities:</p>
<ul>
<li><a href="benchmarks/binary_benchmarks/./configuration/sandbox.html">Sandbox</a></li>
<li><a href="benchmarks/binary_benchmarks/./configuration/exit_code.html">Configure the exit code of the Command</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="delay-the-command"><a class="header" href="#delay-the-command">Delay the Command</a></h1>
<p>Delaying the execution of the <code>Command</code> with <code>Command::delay</code> might be necessary
if the <code>setup</code> is executed in parallel either with <code>Command::setup_parallel</code> or
<code>Command::stdin</code> set to <code>Stdin::Setup</code>.</p>
<p>For example, if you have a server which needs to be started in the setup to be
able to benchmark a client (in our example a crate's binary simply named
<code>client</code>):</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use std::net::{SocketAddr, TcpListener};
use std::time::Duration;
use std::thread;

use iai_callgrind::{
    binary_benchmark, binary_benchmark_group, main, Delay, DelayKind
};

const ADDRESS: &amp;str = "127.0.0.1:31000";

fn setup_tcp_server() {
    println!("Waiting to start server...");
    thread::sleep(Duration::from_millis(300));

    println!("Starting server...");
    let listener = TcpListener::bind(
            ADDRESS.parse::&lt;SocketAddr&gt;().unwrap()
        ).unwrap();

    thread::sleep(Duration::from_secs(1));

    drop(listener);
    println!("Stopped server...");
}

#[binary_benchmark(setup = setup_tcp_server())]
fn bench_client() -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_client"))
        .setup_parallel(true)
        .delay(
            Delay::new(DelayKind::TcpConnect(
                ADDRESS.parse::&lt;SocketAddr&gt;().unwrap(),
            ))
            .timeout(Duration::from_millis(500)),
        )
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_client);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The server is started in the parallel setup function <code>setup_tcp_server</code> since
<code>Command::setup_parallel</code> is set to true. The delay of the <code>Command</code> is
configured with <code>Delay</code> in <code>Command::delay</code> to wait for the tcp connection to be
available. We also applied a timeout of <code>500</code> milliseconds with
<code>Delay::timeout</code>, so if something goes wrong in the server and the tcp
connection cannot be established, the benchmark exits with an error after <code>500</code>
milliseconds instead of hanging forever. After the successful delay, the actual
client is executed and benchmarked. After the exit of the client, the setup is
waited for to exit successfully. Then, if present, the <code>teardown</code> function is
executed.</p>
<p>Please see the library documentation for all possible <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/enum.DelayKind.html"><code>DelayKind</code></a>s and more
details on the <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.Delay.html"><code>Delay</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sandbox"><a class="header" href="#sandbox">Sandbox</a></h1>
<p>The
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.Sandbox.html"><code>Sandbox</code></a>
is a temporary directory which is created before the execution of the <code>setup</code>
and deleted after the <code>teardown</code>. <code>setup</code>, the <code>Command</code> and <code>teardown</code> are
executed inside this temporary directory. This simply describes the order of the
execution but the <code>setup</code> or <code>teardown</code> don't need to be present.</p>
<h2 id="why-using-a-sandbox"><a class="header" href="#why-using-a-sandbox">Why using a Sandbox?</a></h2>
<p>A <code>Sandbox</code> can help mitigating differences in benchmark results on different
machines. As long as <code>$TMP_DIR</code> is unset or set to <code>/tmp</code>, the temporary
directory has a constant length on unix machines (except android
which uses <code>/data/local/tmp</code>). The directory itself is created with a constant
length but random name like <code>/tmp/.a23sr8fk</code>.</p>
<p>It is not implausible that an executable has different event counts just because
the directory it is executed in has a different length. For example, if a member
of your project has set up the project in <code>/home/bob/workspace/our-project</code>
running the benchmarks in this directory, and the ci runs the benchmarks in
<code>/runner/our-project</code>, the event counts might differ. If possible, the
benchmarks should be run in a constant environment. For example <a href="benchmarks/binary_benchmarks/configuration/../important.html">clearing the
environment variables</a> is also such a measure.</p>
<p>Other good reasons for using a <code>Sandbox</code> are convenience, e.g. if you create
files during the <code>setup</code> and <code>Command</code> run and do not want to delete all files
manually. Or, maybe more importantly, if the <code>Command</code> is destructive and
deletes files, it is usually safer to run such a <code>Command</code> in a temporary
directory where it cannot cause damage to your or other file systems.</p>
<p>The <code>Sandbox</code> is deleted after the benchmark, regardless of whether the
benchmark run was successful or not. The latter is not guaranteed if you only
rely on <code>teardown</code>, as <code>teardown</code> is only executed if the <code>Command</code> returns
without error.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
    binary_benchmark, binary_benchmark_group, main, BinaryBenchmarkConfig, Sandbox
};

fn create_file(path: &amp;str) {
    std::fs::write(path, "some content").unwrap();
}

#[binary_benchmark]
#[bench::foo(
    args = ("foo.txt"),
    config = BinaryBenchmarkConfig::default().sandbox(Sandbox::new(true)),
    setup = create_file
)]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>In this example, as part of the <code>setup</code>, the <code>create_file</code> function with the
argument <code>foo.txt</code> is executed in the <code>Sandbox</code> before the <code>Command</code> is
executed. The <code>Command</code> is executed in the same <code>Sandbox</code> and therefore the file
<code>foo.txt</code> with the content <code>some content</code> exists thanks to the <code>setup</code>. After
the execution of the <code>Command</code>, the <code>Sandbox</code> is completely removed, deleting
all files created during <code>setup</code>, the <code>Command</code> execution (and <code>teardown</code> if it
had been present in this example).</p>
<p>Since <code>setup</code> is run in the sandbox, you can't copy fixtures from your project's
workspace into the sandbox that easily anymore. The <code>Sandbox</code> can be configured
to copy <code>fixtures</code> into the temporary directory with <code>Sandbox::fixtures</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
    binary_benchmark, binary_benchmark_group, main, BinaryBenchmarkConfig, Sandbox
};

#[binary_benchmark]
#[bench::foo(
    args = ("foo.txt"),
    config = BinaryBenchmarkConfig::default()
        .sandbox(Sandbox::new(true)
            .fixtures(["benches/foo.txt"])),
)]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The above will copy the fixture file <code>foo.txt</code> in the <code>benches</code> directory into
the sandbox root as <code>foo.txt</code>. Relative paths in <code>Sandbox::fixtures</code> are
interpreted relative to the workspace root. In a multi-crate workspace this is
the directory with the top-level <code>Cargo.toml</code> file. Paths in <code>Sandbox::fixtures</code>
are not limited to files, they can be directories, too.</p>
<p>If you have more complex demands, you can access the workspace root via the
environment variable <code>_WORKSPACE_ROOT</code> in <code>setup</code> and <code>teardown</code>. Suppose, there
is a fixture located in <code>/home/the_project/foo_crate/benches/fixtures/foo.txt</code>
with <code>the_project</code> being the workspace root and <code>foo_crate</code> a workspace member
with the <code>my-foo</code> executable. If the command is expected to create a file
<code>bar.json</code>, which needs further inspection after the benchmarks have run, let's
copy it into a temporary directory <code>tmp</code> (which may or may not exist) in
<code>foo_crate</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
    binary_benchmark, binary_benchmark_group, main, BinaryBenchmarkConfig, Sandbox
};
use std::path::PathBuf;

fn copy_fixture(path: &amp;str) {
    let workspace_root = PathBuf::from(std::env::var_os("_WORKSPACE_ROOT").unwrap());
    std::fs::copy(
        workspace_root.join("foo_crate").join("benches").join("fixtures").join(path),
        path
    );
}

// This function will fail if `bar.json` does not exist, which is fine as this
// file is expected to be created by `my-foo`. So, if this file does not exist,
// an error will occur and the benchmark will fail. Although benchmarks are not
// expected to test the correctness of the application, the `teardown` can be
// used to check postconditions for a successful command run.
fn copy_back(path: &amp;str) {
    let workspace_root = PathBuf::from(std::env::var_os("_WORKSPACE_ROOT").unwrap());
    let dest_dir = workspace_root.join("foo_crate").join("tmp");
    if !dest_dir.exists() {
        std::fs::create_dir(&amp;dest_dir).unwrap();
    }
    std::fs::copy(path, dest_dir.join(path));
}

#[binary_benchmark]
#[bench::foo(
    args = ("foo.txt"),
    config = BinaryBenchmarkConfig::default().sandbox(Sandbox::new(true)),
    setup = copy_fixture,
    teardown = copy_back("bar.json")
)]
fn bench_binary(path: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
        .arg(path)
        .build()
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configure-the-exit-code-of-the-command"><a class="header" href="#configure-the-exit-code-of-the-command">Configure the exit code of the Command</a></h1>
<p>Usually, if a <code>Command</code> exits with a non-zero exit code, the whole benchmark run
fails and stops. If the exit code of the benchmarked <code>Command</code> is to be expected
different from <code>0</code>, the expected exit code can be set in
<code>BinaryBenchmarkConfig::exit_with</code> or <code>Command::exit_with</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
     binary_benchmark, binary_benchmark_group, main, BinaryBenchmarkConfig, ExitWith
};

#[binary_benchmark]
// Here, we set the expected exit code of `my-foo` to 2
#[bench::exit_with_2(
    config = BinaryBenchmarkConfig::default().exit_with(ExitWith::Code(2))
)]
// Here, we don't know the exact exit code but know it is different from 0 (=success)
#[bench::exit_with_failure(
    config = BinaryBenchmarkConfig::default().exit_with(ExitWith::Failure)
)]
fn bench_binary() -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
}

binary_benchmark_group!(name = my_group; benchmarks = bench_binary);
<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="low-level-api"><a class="header" href="#low-level-api">Low-level api</a></h1>
<p>I'm not going into full detail of the low-level api here since it is fully
documented in the <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/index.html">api
Documentation</a>.</p>
<h2 id="the-basic-structure"><a class="header" href="#the-basic-structure">The basic structure</a></h2>
<p>The entry point of the low-level api is the <code>binary_benchmark_group</code></p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
     binary_benchmark, binary_benchmark_attribute, binary_benchmark_group, main,
     BinaryBenchmark, Bench
};

binary_benchmark_group!(
    name = my_group;
    benchmarks = |group: &amp;mut BinaryBenchmarkGroup| {
        group.binary_benchmark(BinaryBenchmark::new("bench_binary")
            .bench(Bench::new("some_id")
                .command(iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-foo"))
                    .arg("foo.txt")
                    .build()
                )
            )
        )
    }
);

<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The low-level api mirrors the high-level api, "structifying" the macros.</p>
<p>The <code>binary_benchmark_group!</code> is also a struct now, the <code>BinaryBenchmarkGroup</code>.
It cannot be instantiated. Instead, it is passed as argument to the expression
of the <code>benchmarks</code> parameter in a <code>binary_benchmark_group</code>. You can choose any
name instead of <code>group</code>, we just have used <code>group</code> throughout the examples.</p>
<p>There's the shorter <code>benchmarks = |group| /* ... */</code> instead of <code>benchmarks = |group: &amp;mut BinaryBenchmarkGroup| /* ... */</code>. We use the more verbose variant
in the examples because it is more informative for benchmarking starters.</p>
<p>Furthermore, the <code>#[library_benchmark]</code> macro correlates with
<code>iai_callgrind::LibraryBenchmark</code> and <code>#[bench]</code> with <code>iai_callgrind::Bench</code>.
The parameters of the macros are now functions in the respective structs. The
return value of the benchmark function, the <code>iai-callgrind::Command</code>, is now
also a function <code>iai-callgrind::Bench::command</code>.</p>
<p>Note there is no <code>iai-callgrind::Benches</code> struct since specifying multiple
commands with <code>iai_callgrind::Bench::command</code> behaves exactly the same way as
the <code>#[benches]</code> attribute. So, the <code>file</code> parameter of <code>#[benches]</code> is a part
of <code>iai-callgrind::Bench</code> and can be used with the <code>iai-callgrind::Bench::file</code>
function.</p>
<h2 id="intermixing-high-level-and-low-level-api"><a class="header" href="#intermixing-high-level-and-low-level-api">Intermixing high-level and low-level api</a></h2>
<p>It is recommended to start with the high-level api using the
<code>#[binary_benchmark]</code> attribute, since you can fall back to the low-level api in
a few steps with the <code>binary_benchmark_attribute!</code> macro as shown below. The
other way around is much more involved.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">macro_rules! env { ($m:tt) =&gt; {{ "/some/path" }} }
</span>use iai_callgrind::{
     binary_benchmark, binary_benchmark_attribute, binary_benchmark_group, main,
     BinaryBenchmark, Bench
};

#[binary_benchmark]
#[bench::some_id("foo")]
fn attribute_benchmark(arg: &amp;str) -&gt; iai_callgrind::Command {
    iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-binary"))
        .arg(arg)
        .build()
}

binary_benchmark_group!(
    name = low_level;
    benchmarks = |group: &amp;mut BinaryBenchmarkGroup| {
        group
            .binary_benchmark(binary_benchmark_attribute!(attribute_benchmark))
            .binary_benchmark(
                BinaryBenchmark::new("low_level_benchmark")
                    .bench(
                        Bench::new("some_id").command(
                            iai_callgrind::Command::new(env!("CARGO_BIN_EXE_my-binary"))
                                .arg("bar")
                                .build()
                        )
                    )
            )
    }
);

<span class="boring">fn main() {
</span>main!(binary_benchmark_groups = low_level);
<span class="boring">}</span></code></pre></pre>
<p>As shown above, there's no need to transcribe the function <code>attribute_benchmark</code>
with the <code>#[binary_benchmark]</code> attribute into the low-level api structures. Just
keep it as it is and add it to a the <code>group</code> with
<code>group.binary_benchmark(binary_benchmark_attribute(attribute_benchmark))</code>.
That's it! You can continue hacking on your benchmarks in the low-level api.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="more-examples-needed"><a class="header" href="#more-examples-needed">More examples needed?</a></h1>
<p>As in <a href="benchmarks/binary_benchmarks/../library_benchmarks/examples.html">library benchmarks</a>, I'm referring
here to the <a href="https://github.com/iai-callgrind/iai-callgrind">github repository</a>.
The binary benchmarks functionality of Iai-Callgrind is tested with system tests
in the private
<a href="https://github.com/iai-callgrind/iai-callgrind/tree/main/benchmark-tests/benches/test_lib_bench">benchmark-tests</a>
package.</p>
<p>Each system test there can serve you as an example, but for a fully documented
and commented one see
<a href="https://github.com/iai-callgrind/iai-callgrind/blob/main/benchmark-tests/benches/test_bin_bench/intro/test_bin_bench_intro.rs">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="performance-regressions"><a class="header" href="#performance-regressions">Performance Regressions</a></h1>
<p>With Iai-Callgrind you can define limits for each event kinds over which a
performance regression can be assumed. Per default, Iai-Callgrind does not
perform default regression checks, and you have to opt-in with a
<code>RegressionConfig</code> at benchmark level with a <code>LibraryBenchmarkConfig</code> or
<code>BinaryBenchmarkConfig</code> or at a global level with <a href="./cli_and_env/basics.html">Command-line arguments or
Environment variables</a>.</p>
<h2 id="define-a-performance-regression"><a class="header" href="#define-a-performance-regression">Define a performance regression</a></h2>
<p>A performance regression check consists of an <code>EventKind</code> and a percentage. If
the percentage is negative, then a regression is assumed to be below this limit.</p>
<p>The default <code>EventKind</code> is <code>EventKind::Ir</code> with a value of <code>+10%</code>.</p>
<p>For example, in a <a href="./benchmarks/library_benchmarks/configuration.html">Library
Benchmark</a>, define a limit of
<code>+5%</code> for the total instructions executed (the <code>Ir</code> event kind) in all
benchmarks of this file :</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{
    library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
    RegressionConfig, EventKind
};
use std::hint::black_box;

#[library_benchmark]
fn bench_library() -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(vec![3, 2, 1]))
}

library_benchmark_group!(name = my_group; benchmarks = bench_library);

<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .regression(
            RegressionConfig::default()
                .limits([(EventKind::Ir, 5.0)])
        );
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>Now, if the comparison of the <code>Ir</code> events of the current <code>bench_library</code>
benchmark run with the previous run results in an increase of over 5%, the
benchmark fails. Please, also have a look at the <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/struct.RegressionConfig.html"><code>api docs</code></a>
for further configuration options.</p>
<p>Running the benchmark from above the first time results in the following output:</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::bench_library</span>
  Instructions:     <b>            215</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            288</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              0</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              7</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            295</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            533</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>Let's assume there's a change in <code>my_lib::bubble_sort</code> which has increased the
instruction counts, then running the benchmark again results in an output
something similar to this:</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::bench_library</span>
  Instructions:     <b>            281</b>|215             (<b><span style="color:#F55">+30.6977%</span></b>) [<b><span style="color:#F55">+1.30698x</span></b>]
  L1 Hits:          <b>            374</b>|288             (<b><span style="color:#F55">+29.8611%</span></b>) [<b><span style="color:#F55">+1.29861x</span></b>]
  L2 Hits:          <b>              0</b>|0               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              8</b>|7               (<b><span style="color:#F55">+14.2857%</span></b>) [<b><span style="color:#F55">+1.14286x</span></b>]
  Total read+write: <b>            382</b>|295             (<b><span style="color:#F55">+29.4915%</span></b>) [<b><span style="color:#F55">+1.29492x</span></b>]
  Estimated Cycles: <b>            654</b>|533             (<b><span style="color:#F55">+22.7017%</span></b>) [<b><span style="color:#F55">+1.22702x</span></b>]
Performance has <b><span style="color:#F55">regressed</span></b>: <b>Instructions</b> (281 > 215) regressed by <b><span style="color:#F55">+30.6977%</span></b> (><span style="color:#555">+5.00000</span>)
iai_callgrind_runner: <b><span style="color:#A00">Error</span></b>: Performance has regressed.
error: bench failed, to rerun pass `-p the-crate --bench my_benchmark`

Caused by:
  process didn't exit successfully: `/path/to/your/project/target/release/deps/my_benchmark-a9b36fec444944bd --bench` (exit status: 1)
error: Recipe `bench-test` failed on line 175 with exit code 1</code></pre>
<h2 id="which-event-to-choose-to-measure-performance-regressions"><a class="header" href="#which-event-to-choose-to-measure-performance-regressions">Which event to choose to measure performance regressions?</a></h2>
<p>If in doubt, the definite answer is <code>Ir</code> (instructions executed). If <code>Ir</code> event
counts decrease noticeable the function (binary) runs faster. The inverse
statement is also true: If the <code>Ir</code> counts increase noticeable, there's a
slowdown of the function (binary).</p>
<p>These statements are not so easy to transfer to <code>Estimated Cycles</code> and the other
event counts. But, depending on the scenario and the function (binary) under
test, it can be reasonable to define more regression checks.</p>
<h2 id="who-actually-uses-instructions-to-measure-performance"><a class="header" href="#who-actually-uses-instructions-to-measure-performance">Who actually uses instructions to measure performance?</a></h2>
<p>The ones known to the author of this humble guide are</p>
<ul>
<li><a href="https://sqlite.org/cpu.html#performance_measurement">SQLite</a>: They use mainly
cpu instructions to measure performance improvements (and regressions).</li>
<li>Also in benchmarks of the <a href="https://github.com/rust-lang/rustc-perf">rustc</a>
compiler, instruction counts play a great role. But, they also use cache
metrics and cycles.</li>
</ul>
<p>If you know of others, please feel free to
<a href="https://github.com/iai-callgrind/iai-callgrind/master/docs/src/regressions.md">add</a>
them to this list.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="other-valgrind-tools"><a class="header" href="#other-valgrind-tools">Other Valgrind Tools</a></h1>
<p>In addition to the default benchmarks, you can use the Iai-Callgrind framework
to run other Valgrind profiling <code>Tool</code>s like <code>DHAT</code>, <code>Massif</code> and the
experimental <code>BBV</code> but also <code>Memcheck</code>, <code>Helgrind</code> and <code>DRD</code> if you need to
check memory and thread safety of benchmarked code. See also the <a href="https://valgrind.org/docs/manual/manual.html">Valgrind User
Manual</a> for more details and
command line arguments. The additional tools can be specified in a
<code>LibraryBenchmarkConfig</code> or <code>BinaryBenchmarkConfig</code>. For example to run <code>DHAT</code>
for all library benchmarks in addition to <code>Callgrind</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{
    library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig, 
    Tool, ValgrindTool
};
use std::hint::black_box;

#[library_benchmark]
fn bench_library() -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(vec![3, 2, 1]))
}

library_benchmark_group!(name = my_group; benchmarks = bench_library);

<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .tool(Tool::new(ValgrindTool::DHAT));
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>All tools which produce an <code>ERROR SUMMARY</code> <code>(Memcheck, DRD, Helgrind)</code> have
<a href="https://valgrind.org/docs/manual/manual-core.html#manual-core.erropts"><code>--error-exitcode=201</code></a>
set, so if there are any errors, the benchmark run fails with <code>201</code>. You can
overwrite this default with</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{Tool, ValgrindTool};

Tool::new(ValgrindTool::Memcheck).args(["--error-exitcode=0"]);
<span class="boring">}</span></code></pre></pre>
<p>which would restore the default of <code>0</code> from valgrind.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="valgrind-client-requests-1"><a class="header" href="#valgrind-client-requests-1">Valgrind Client Requests</a></h1>
<p>Iai-Callgrind ships with its own interface to the <a href="https://valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.clientreq">Valgrind's Client Request
Mechanism</a>.
Iai-Callgrind's client requests have zero overhead (relative to the "C"
implementation of Valgrind) on many targets which are also natively supported by
valgrind. In short, Iai-Callgrind provides a complete and performant
implementation of Valgrind Client Requests.</p>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Client requests are deactivated by default but can be activated with the
<code>client_requests</code> feature.</p>
<pre><code class="language-toml">[dev-dependencies]
iai-callgrind = { version = "0.14.1", features = ["client_requests"] }
</code></pre>
<p>If you need the client requests in your production code, you don't want them to
do anything when not running under valgrind with Iai-Callgrind benchmarks. You
can achieve that by adding Iai-Callgrind with the <code>client_requests_defs</code> feature
to your runtime dependencies and with the <code>client_requests</code> feature to your
<code>dev-dependencies</code> like so:</p>
<pre><code class="language-toml">[dependencies]
iai-callgrind = { version = "0.14.1", default-features = false, features = [
    "client_requests_defs"
] }

[dev-dependencies]
iai-callgrind = { version = "0.14.1", features = ["client_requests"] }
</code></pre>
<p>With just the <code>client_requests_defs</code> feature activated, the client requests
compile down to nothing and don't add any overhead to your production code. It
simply provides the "definitions", method signatures and macros without body.
Only with the activated <code>client_requests</code> feature they will be actually
executed. Note that the client requests do not depend on any other part of
Iai-Callgrind, so you could even use the client requests without the rest of
Iai-Callgrind.</p>
<p>When building Iai-Callgrind with client requests, the valgrind header files must
exist in your standard include path (most of the time <code>/usr/include</code>). This is
usually the case if you've installed valgrind with your distribution's package
manager. If not, you can point the <code>IAI_CALLGRIND_VALGRIND_INCLUDE</code> or
<code>IAI_CALLGRIND_&lt;triple&gt;_VALGRIND_INCLUDE</code> environment variables to the include
path. So, if the headers can be found in <code>/home/foo/repo/valgrind/{valgrind.h, callgrind.h, ...}</code>, the correct include path would be
<code>IAI_CALLGRIND_VALGRIND_INCLUDE=/home/foo/repo</code> (not <code>/home/foo/repo/valgrind</code>)</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>Use them in your code for example like so:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::client_requests;

<span class="boring">fn main() {
</span>fn main() {
    // Start callgrind event counting if not already started earlier
    client_requests::callgrind::start_instrumentation();

    // do something important

    // Switch event counting off
    client_requests::callgrind::stop_instrumentation();
}
<span class="boring">}</span></code></pre></pre>
<h3 id="library-benchmarks-1"><a class="header" href="#library-benchmarks-1">Library Benchmarks</a></h3>
<p>In <a href="./benchmarks/library_benchmarks.html">library benchmarks</a> you might need to
use <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/enum.EntryPoint.html"><code>EntryPoint::None</code></a> in order to make the client requests work
as expected:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

pub mod my_lib {
     #[inline(never)]
     fn bubble_sort(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         // The algorithm
<span class="boring">       input
</span>     }

     pub fn pre_bubble_sort(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         println!("Doing something before the function call");
         iai_callgrind::client_requests::callgrind::start_instrumentation();

         let result = bubble_sort(input);

         iai_callgrind::client_requests::callgrind::stop_instrumentation();
         result
     }
}

#[library_benchmark]
#[bench::small(vec![3, 2, 1])]
#[bench::bigger(vec![5, 4, 3, 2, 1])]
fn bench_function(array: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::pre_bubble_sort(array))
}

library_benchmark_group!(name = my_group; benchmarks = bench_function);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>The default <a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/enum.EntryPoint.html"><code>EntryPoint</code></a> sets the <a href="https://valgrind.org/docs/manual/cl-manual.html#cl-manual.options"><code>--toggle-collect</code></a> to the benchmark function (here <code>bench_function</code>) and
<code>--collect-at-start=no</code>. So, <code>Callgrind</code> starts collecting the events when
entering the benchmark function, not the moment <code>start_instrumentation</code> is
called. This behaviour can be remedied with <code>EntryPoint::None</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{
    main, library_benchmark_group, library_benchmark, LibraryBenchmarkConfig,
    client_requests, EntryPoint
};
use std::hint::black_box;

pub mod my_lib {
     #[inline(never)]
     fn bubble_sort(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         // The algorithm
<span class="boring">       input
</span>     }

     pub fn pre_bubble_sort(input: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
         println!("Doing something before the function call");
         iai_callgrind::client_requests::callgrind::start_instrumentation();

         let result = bubble_sort(input);

         iai_callgrind::client_requests::callgrind::stop_instrumentation();
         result
     }
}

#[library_benchmark(
    config = LibraryBenchmarkConfig::default()
        .callgrind_args(["--collect-at-start=no"])
        .entry_point(EntryPoint::None)
)]
#[bench::small(vec![3, 2, 1])]
#[bench::bigger(vec![5, 4, 3, 2, 1])]
fn bench_function(array: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::pre_bubble_sort(array))
}

library_benchmark_group!(name = my_group; benchmarks = bench_function);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>As the standard toggle is now switched off and the option
<code>--collect-at-start=no</code> is also omitted, you must specify
<code>--collect-at-start=no</code> manually in
<code>LibraryBenchmarkConfig::raw_callgrind_args</code>.</p>
<p>Please see the
<a href="https://docs.rs/iai-callgrind/0.14.1/iai_callgrind/client_requests"><code>docs</code></a> for
more details!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="callgrind-flamegraphs"><a class="header" href="#callgrind-flamegraphs">Callgrind Flamegraphs</a></h1>
<p>Flamegraphs are opt-in and can be created if you pass a <code>FlamegraphConfig</code> to
the <code>BinaryBenchmarkConfig</code> or <code>LibraryBenchmarkConfig</code>. Callgrind flamegraphs
are meant as a complement to valgrind's visualization tools
<code>callgrind_annotate</code> and <code>kcachegrind</code>.</p>
<p>For example create all kind of flamegraphs for all benchmarks in a library
benchmark:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{
    library_benchmark, library_benchmark_group, main, LibraryBenchmarkConfig,
    FlamegraphConfig
};
use std::hint::black_box;

#[library_benchmark]
fn bench_library() -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(vec![3, 2, 1]))
}

library_benchmark_group!(name = my_group; benchmarks = bench_library);

<span class="boring">fn main() {
</span>main!(
    config = LibraryBenchmarkConfig::default()
        .flamegraph(FlamegraphConfig::default());
    library_benchmark_groups = my_group
);
<span class="boring">}</span></code></pre></pre>
<p>The produced flamegraph <code>*.svg</code> files are located next to the respective
callgrind output file in the <code>target/iai</code>
<a href="./cli_and_env/output/out_directory.html">directory</a>.</p>
<h2 id="regular-flamegraphs"><a class="header" href="#regular-flamegraphs">Regular Flamegraphs</a></h2>
<p>Regular callgrind flamegraphs show the inclusive costs for functions and a
single <code>EventKind</code> (default is <code>EventKind::Ir</code>), similar to
<code>callgrind_annotate</code>. Suppose the example from above is stored in a benchmark
<code>iai_callgrind_benchmark</code>:</p>
<p><img src="./images/flamegraph_regular.svg" alt="Regular Flamegraph" /></p>
<p>If you open this image in a new tab, you can play around with the svg.</p>
<h2 id="differential-flamegraphs"><a class="header" href="#differential-flamegraphs">Differential Flamegraphs</a></h2>
<p>Differential flamegraphs facilitate a deeper understanding of code sections
which cause a bottleneck or a performance regressions etc.</p>
<p><img src="./images/flamegraph_diff.svg" alt="Differential Flamegraph" /></p>
<p>We simulated a small change in <code>bubble_sort</code> and in the differential flamegraph
you can spot fairly easily where the increase of <code>Instructions</code> is happening.</p>
<h2 id="experimental-create-flamegraphs-for-multi-threadedmulti-process-benchmarks"><a class="header" href="#experimental-create-flamegraphs-for-multi-threadedmulti-process-benchmarks">(Experimental) Create flamegraphs for multi-threaded/multi-process benchmarks</a></h2>
<p>Note the following only affects flamegraphs of multi-threaded/multi-process
benchmarks and benchmarks which produce multiple parts with a total over all
sub-metrics.</p>
<p>Currently, Iai-Callgrind creates the flamegraphs only for the total over all
threads/parts and subprocesses. This leads to complications since the call graph
is not be fully recovered just by examining each thread/subprocess separately.
So, the total metrics in the flamegraphs might not be the same as the total
metrics shown in the terminal output. If in doubt, the terminal output shows the
the correct metrics.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-usage"><a class="header" href="#basic-usage">Basic usage</a></h1>
<p>It's possible to pass arguments to Iai-Callgrind separated by <code>--</code> (<code>cargo bench -- ARGS</code>). If you're running into the error <code>Unrecognized Option</code>, see
<a href="cli_and_env/../troubleshooting/running-cargo-bench-results-in-an-unrecognized-option-error.html">Troubleshooting</a>.
For a complete rundown of possible arguments, execute <code>cargo bench --bench &lt;benchmark&gt; -- --help</code>. Almost all command-line arguments have a corresponding
environment variable. The environment variables which don't have a corresponding
command-line argument are:</p>
<ul>
<li><code>IAI_CALLGRIND_COLOR</code>: <a href="cli_and_env/./output/color.html">Control the colored output of Iai-Callgrind</a> (Default
is <code>auto</code>)</li>
<li><code>IAI_CALLGRIND_LOG</code>: <a href="cli_and_env/./output/logging.html">Define the log level</a> (Default is <code>WARN</code>)</li>
</ul>
<h2 id="the-command-line-arguments"><a class="header" href="#the-command-line-arguments">The command-line arguments</a></h2>
<pre><code class="language-text">High-precision and consistent benchmarking framework/harness for Rust

Boolish command line arguments take also one of `y`, `yes`, `t`, `true`, `on`,
`1`
instead of `true` and one of `n`, `no`, `f`, `false`, `off`, and `0` instead of
`false`

Usage: cargo bench ... [BENCHNAME] -- [OPTIONS]

Arguments:
  [BENCHNAME]
          If specified, only run benches containing this string in their names

          Note that a benchmark name might differ from the benchmark file name.

          [env: IAI_CALLGRIND_FILTER=]

          Options:
      --callgrind-args &lt;CALLGRIND_ARGS&gt;
          The raw arguments to pass through to Callgrind

          This is a space separated list of command-line-arguments specified as
          if they were
          passed directly to valgrind.

          Examples:
            * --callgrind-args=--dump-instr=yes
            * --callgrind-args='--dump-instr=yes --collect-systime=yes'

          [env: IAI_CALLGRIND_CALLGRIND_ARGS=]

      --save-summary[=&lt;SAVE_SUMMARY&gt;]
          Save a machine-readable summary of each benchmark run in json format
          next to the usual benchmark output

          [env: IAI_CALLGRIND_SAVE_SUMMARY=]

          Possible values:
          - json:        The format in a space optimal json representation
          without newlines
          - pretty-json: The format in pretty printed json

      --allow-aslr[=&lt;ALLOW_ASLR&gt;]
          Allow ASLR (Address Space Layout Randomization)

          If possible, ASLR is disabled on platforms that support it (linux,
          freebsd) because ASLR could noise up the callgrind cache simulation results a
          bit. Setting this option to true runs all benchmarks with ASLR enabled.

          See also
          &lt;https://docs.kernel.org/admin-guide/sysctl/kernel.html?
          highlight=randomize_va_space#randomize-va-space&gt;

          [env: IAI_CALLGRIND_ALLOW_ASLR=]
          [possible values: true, false]

      --regression &lt;REGRESSION&gt;
          Set performance regression limits for specific `EventKinds`

          This is a `,` separate list of EventKind=limit (key=value) pairs with
          the limit being a positive or negative percentage. If positive, a performance
          regression check for this `EventKind` fails if the limit is exceeded. If
          negative, the regression check fails if the value comes below the limit. The
          `EventKind` is matched case-insensitive. For a list of valid `EventKinds` see
          the docs:
          &lt;https://docs.rs/iai-callgrind/latest/iai_callgrind/enum.EventKind.html&gt;

          Examples: --regression='ir=0.0' or --regression='ir=0,
          EstimatedCycles=10'

          [env: IAI_CALLGRIND_REGRESSION=]

      --regression-fail-fast[=&lt;REGRESSION_FAIL_FAST&gt;]
          If true, the first failed performance regression check fails the
          whole benchmark run

          This option requires `--regression=...` or
          `IAI_CALLGRIND_REGRESSION=...` to be present.

          [env: IAI_CALLGRIND_REGRESSION_FAIL_FAST=]
          [possible values: true, false]

      --save-baseline[=&lt;SAVE_BASELINE&gt;]
          Compare against this baseline if present and then overwrite it

          [env: IAI_CALLGRIND_SAVE_BASELINE=]

      --baseline[=&lt;BASELINE&gt;]
          Compare against this baseline if present but do not overwrite it

          [env: IAI_CALLGRIND_BASELINE=]

      --load-baseline[=&lt;LOAD_BASELINE&gt;]
          Load this baseline as the new data set instead of creating a new one

          [env: IAI_CALLGRIND_LOAD_BASELINE=]

      --output-format &lt;OUTPUT_FORMAT&gt;
          The terminal output format in default human-readable format or in
          machine-readable json format

          # The JSON Output Format

          The json terminal output schema is the same as the schema with the
          `--save-summary` argument when saving to a `summary.json` file. All other
          output than the json output goes to stderr and only the summary output goes to
          stdout. When not printing pretty json, each line is a dictionary summarizing a
          single benchmark. You can combine all lines (benchmarks) into an array for
          example with `jq`

          `cargo bench -- --output-format=json | jq -s`

          which transforms `{...}\n{...}` into `[{...},{...}]`

          [env: IAI_CALLGRIND_OUTPUT_FORMAT=]
          [default: default]
          [possible values: default, json, pretty-json]

      --separate-targets[=&lt;SEPARATE_TARGETS&gt;]
          Separate iai-callgrind benchmark output files by target

          The default output path for files created by iai-callgrind and
          valgrind during the benchmark is


          `target/iai/$PACKAGE_NAME/$BENCHMARK_FILE/$GROUP/$BENCH_FUNCTION.$BENCH_ID`.

          This can be problematic if you're running the benchmarks not only for
          a single target because you end up comparing the benchmark runs with the wrong
          targets. Setting this option changes the default output path to


          `target/iai/$TARGET/$PACKAGE_NAME/$BENCHMARK_FILE/$GROUP/
              $BENCH_FUNCTION.$BENCH_ID`

          Although not as comfortable and strict, you could achieve a
          separation by target also with baselines and a combination of
          `--save-baseline=$TARGET` and `--baseline=$TARGET` if you prefer having all
          files of a single $BENCH in the same directory.

          [env: IAI_CALLGRIND_SEPARATE_TARGETS=]
          [default: false]
          [possible values: true, false]

      --home &lt;HOME&gt;
          Specify the home directory of iai-callgrind benchmark output files

          All output files are per default stored under the
          `$PROJECT_ROOT/target/iai` directory. This option lets you customize this
          home directory, and it will be created if it doesn't exist.

          [env: IAI_CALLGRIND_HOME=]

      --nocapture[=&lt;NOCAPTURE&gt;]
          Don't capture terminal output of benchmarks

          Possible values are one of [true, false, stdout, stderr].

          This option is currently restricted to the `callgrind` run of
          benchmarks. The output of additional tool runs like DHAT, Memcheck, ... is
          still captured, to prevent showing the same output of benchmarks multiple
          times. Use `IAI_CALLGRIND_LOG=info` to also show captured and logged output.

          If no value is given, the default missing value is `true` and doesn't
          capture stdout and stderr. Besides `true` or `false` you can specify the
          special values `stdout` or `stderr`. If `--nocapture=stdout` is given, the
          output to `stdout` won't be captured and the output to `stderr` will be
          discarded. Likewise, if `--nocapture=stderr` is specified, the output to
          `stderr` won't be captured and the output to `stdout` will be discarded.

          [env: IAI_CALLGRIND_NOCAPTURE=]
          [default: false]

  -h, --help
          Print help (see a summary with '-h')

  -V, --version
          Print version
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="comparing-with-baselines"><a class="header" href="#comparing-with-baselines">Comparing with baselines</a></h1>
<p>Usually, two consecutive benchmark runs let Iai-Callgrind compare these two
runs. It's sometimes desirable to compare the current benchmark run against a
static reference, instead. For example, if you're working longer on the
implementation of a feature, you may wish to compare against a baseline from
another branch or the commit from which you started off hacking on your new
feature to make sure you haven't introduced performance regressions.
Iai-Callgrind offers such custom baselines. If you are familiar with
<a href="https://bheisler.github.io/criterion.rs/book/user_guide/command_line_options.html#baselines">criterion.rs</a>,
the following command line arguments should also be very familiar to you:</p>
<ul>
<li><code>--save-baseline=NAME</code> (env: <code>IAI_CALLGRIND_SAVE_BASELINE</code>): Compare against
the <code>NAME</code> baseline if present and then overwrite it.</li>
<li><code>--baseline=NAME</code> (env: <code>IAI_CALLGRIND_BASELINE</code>): Compare against the <code>NAME</code>
baseline without overwriting it</li>
<li><code>--load-baseline=NAME</code> (env: <code>IAI_CALLGRIND_LOAD_BASELINE</code>): Load the <code>NAME</code>
baseline as the <code>new</code> data set instead of creating a new one. This option
needs also <code>--baseline=NAME</code> to be present.</li>
</ul>
<p>If <code>NAME</code> is not present, <code>NAME</code> defaults to <code>default</code>.</p>
<p>For example to create a static reference from the main branch and compare it:</p>
<pre><code class="language-shell">git checkout main
cargo bench --bench &lt;benchmark&gt; -- --save-baseline=main
git checkout feature
# ... HACK ... HACK
cargo bench --bench &lt;benchmark&gt; -- --baseline main
</code></pre>
<p>Sticking to the above execution sequence,</p>
<pre><code class="language-shell">cargo bench --bench my_benchmark -- --save-baseline=main
</code></pre>
<p>prints something like that with an additional line <code>Baselines</code> in the output.</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::bench_library</span>
  Baselines:        <b>           main</b>|main
  Instructions:     <b>            280</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>            374</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              1</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>              6</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>            381</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>            589</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>After you've made some changes to your code, running</p>
<pre><code class="language-shell">cargo bench --bench my_benchmark -- --baseline=main`
</code></pre>
<p>prints something like the following:</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::bench_library</span>
  Baselines:                       |main
  Instructions:     <b>            214</b>|280             (<b><span style="color:#42c142">-23.5714%</span></b>) [<b><span style="color:#42c142">-1.30841x</span></b>]
  L1 Hits:          <b>            287</b>|374             (<b><span style="color:#42c142">-23.2620%</span></b>) [<b><span style="color:#42c142">-1.30314x</span></b>]
  L2 Hits:          <b>              1</b>|1               (<span style="color:#555">No change</span>)
  RAM Hits:         <b>              6</b>|6               (<span style="color:#555">No change</span>)
  Total read+write: <b>            294</b>|381             (<b><span style="color:#42c142">-22.8346%</span></b>) [<b><span style="color:#42c142">-1.29592x</span></b>]
  Estimated Cycles: <b>            502</b>|589             (<b><span style="color:#42c142">-14.7708%</span></b>) [<b><span style="color:#42c142">-1.17331x</span></b>]</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="controlling-the-output-of-iai-callgrind"><a class="header" href="#controlling-the-output-of-iai-callgrind">Controlling the output of Iai-Callgrind</a></h1>
<p>This section describes command-line options and environment variables which
influence the terminal, file and logging output of Iai-Callgrind.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="customize-the-output-directory"><a class="header" href="#customize-the-output-directory">Customize the output directory</a></h1>
<p>All output files of Iai-Callgrind are usually stored using the following scheme:</p>
<p><code>$WORKSPACE_ROOT/target/iai/$PACKAGE_NAME/$BENCHMARK_FILE/$GROUP/$BENCH_FUNCTION.$BENCH_ID</code></p>
<p>This directory structure can partly be changed with the following options.</p>
<h2 id="callgrind-home"><a class="header" href="#callgrind-home">Callgrind Home</a></h2>
<p>Per default, all benchmark output files are stored under the
<code>$WORKSPACE_ROOT/target/iai</code> directory tree. This home directory can be changed
with the <code>IAI_CALLGRIND_HOME</code> environment variable or the command-line argument
<code>--home</code>. The command-line argument overwrites the value of the environment
variable. For example to store all files under the <code>/tmp/iai-callgrind</code>
directory you can use <code>IAI_CALLGRIND_HOME=/tmp/iai-callgrind</code> or <code>cargo bench -- --home=/tmp/iai-callgrind</code>.</p>
<h2 id="separate-targets"><a class="header" href="#separate-targets">Separate targets</a></h2>
<p>If you're running the benchmarks on different targets, it's necessary to
separate the output files of the benchmark runs per target or else you could end
up comparing the benchmarks with the wrong target leading to strange results.
You can achieve this with different baselines per target, but it's much less
painful to separate the output files by target with the <code>--separate-targets</code>
command-line argument or setting the environment variable
<code>IAI_CALLGRIND_SEPARATE_TARGETS=yes</code>). The output directory structure
changes from</p>
<p><code>target/iai/$PACKAGE_NAME/$BENCHMARK_FILE/$GROUP/$BENCH_FUNCTION.$BENCH_ID</code></p>
<p>to</p>
<p><code>target/iai/$TARGET_TRIPLE/$PACKAGE_NAME/$BENCHMARK_FILE/$GROUP/$BENCH_FUNCTION.$BENCH_ID</code></p>
<p>For example, assuming the library benchmark file name is <code>bench_file</code> in the
package <code>my_package</code></p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span><span class="boring">mod my_lib { pub fn bubble_sort(_: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; { vec![] } }
</span>use iai_callgrind::{main, library_benchmark_group, library_benchmark};
use std::hint::black_box;

#[library_benchmark]
#[bench::short(vec![4, 3, 2, 1])]
fn bench_bubble_sort(values: Vec&lt;i32&gt;) -&gt; Vec&lt;i32&gt; {
    black_box(my_lib::bubble_sort(values))
}

library_benchmark_group!(name = my_group; benchmarks = bench_bubble_sort);

<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>Without <code>--separate-targets</code>:</p>
<p><code>target/iai/my_package/bench_file/my_group/bench_bubble_sort.short</code></p>
<p>and with <code>--separate-targets</code> assuming you're running the benchmark on the
<code>x86_64-unknown-linux-gnu</code> target:</p>
<p><code>target/iai/x86_64-unknown-linux-gnu/my_package/bench_file/my_group/bench_bubble_sort.short</code></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="machine-readable-output"><a class="header" href="#machine-readable-output">Machine-readable output</a></h1>
<p>With <code>--output-format=default|json|pretty-json</code> (env:
<code>IAI_CALLGRIND_OUTPUT_FORMAT</code>) you can change the terminal output format to the
machine-readable json format. The json schema fully describing the json output
is stored in
<a href="https://github.com/iai-callgrind/iai-callgrind/blob/main/iai-callgrind-runner/schemas/summary.v2.schema.json">summary.v2.schema.json</a>.
Each line of json output (if not <code>pretty-json</code>) is a summary of a single
benchmark, and you may want to combine all benchmarks in an array. You can do so
for example with <code>jq</code></p>
<p><code>cargo bench -- --output-format=json | jq -s</code></p>
<p>which transforms <code>{...}\n{...}</code> into <code>[{...},{...}]</code>.</p>
<p>Instead of, or in addition to changing the terminal output, it's possible to
save a summary file for each benchmark with <code>--save-summary=json|pretty-json</code>
(env: <code>IAI_CALLGRIND_SAVE_SUMMARY</code>). The <code>summary.json</code> files are stored next to
the usual benchmark output files in the <code>target/iai</code> directory.</p>
<div style="break-before: page; page-break-before: always;"></div><!-- markdownlint-disable MD041 MD033 -->
<h1 id="showing-terminal-output-of-benchmarks"><a class="header" href="#showing-terminal-output-of-benchmarks">Showing terminal output of benchmarks</a></h1>
<p>Per default, all terminal output of the benchmark function, <code>setup</code> and
<code>teardown</code> is captured and therefore not shown during a benchmark run.</p>
<h2 id="using-the-log-level"><a class="header" href="#using-the-log-level">Using the log level</a></h2>
<p>The most basic possibility to show any captured output, is to use
<a href="cli_and_env/output/./logging.html"><code>IAI_CALLGRIND_LOG=info</code></a>. This includes a lot of other output,
too.</p>
<h2 id="tell-iai-callgrind-to-not-capture-the-output"><a class="header" href="#tell-iai-callgrind-to-not-capture-the-output">Tell Iai-Callgrind to not capture the output</a></h2>
<p>Another nicer possibility is, to tell Iai-Callgrind to not capture output with
the <code>--nocapture</code> (env: <code>IAI_CALLGRIND_NOCAPTURE</code>) option. This is currently
restricted to the <code>callgrind</code> run to prevent showing the same output multiple
times. So, any terminal output of <a href="cli_and_env/output/../../tools.html">other tool runs</a> is still
captured.</p>
<p>The <code>--nocapture</code> flag takes the special values <code>stdout</code> and <code>stderr</code> in
addition to <code>true</code> and <code>false</code>:</p>
<p><code>--nocapture=true|false|stdout|stderr</code></p>
<p>In the <code>--nocapture=stdout</code> case, terminal output to <code>stdout</code> is not captured
and shown during the benchmark run but output to <code>stderr</code> is discarded.
Likewise, <code>--nocapture=stderr</code> shows terminal output to <code>stderr</code> but discards
output to <code>stdout</code>.</p>
<p>Let's take as example a library benchmark <code>benches/my_benchmark.rs</code></p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate iai_callgrind;
</span>use iai_callgrind::{library_benchmark, library_benchmark_group, main};
use std::hint::black_box;

fn print_to_stderr(value: u64) {
    eprintln!("Error output during teardown: {value}");
}

fn add_10_and_print(value: u64) -&gt; u64 {
    let value = value + 10;
    println!("Output to stdout: {value}");

    value
}

#[library_benchmark]
#[bench::some_id(args = (10), teardown = print_to_stderr)]
fn bench_library(value: u64) -&gt; u64 {
    black_box(add_10_and_print(value))
}

library_benchmark_group!(name = my_group; benchmarks = bench_library);
<span class="boring">fn main() {
</span>main!(library_benchmark_groups = my_group);
<span class="boring">}</span></code></pre></pre>
<p>If the above benchmark is run with <code>cargo bench --bench my_benchmark -- --nocapture</code>, the output of Iai-Callgrind will look like this:</p>
<pre><code class="hljs"><span style="color:#0A0">my_benchmark::my_group::bench_library</span> <span style="color:#0AA">some_id</span><span style="color:#0AA">:</span><b><span style="color:#00A">10</span></b>
Output to stdout: 20
Error output during teardown: 20
<span style="color:#A50">-</span> <span style="color:#A50">end of stdout/stderr</span>
  Instructions:     <b>            851</b>|N/A             (<span style="color:#555">*********</span>)
  L1 Hits:          <b>           1193</b>|N/A             (<span style="color:#555">*********</span>)
  L2 Hits:          <b>              5</b>|N/A             (<span style="color:#555">*********</span>)
  RAM Hits:         <b>             66</b>|N/A             (<span style="color:#555">*********</span>)
  Total read+write: <b>           1264</b>|N/A             (<span style="color:#555">*********</span>)
  Estimated Cycles: <b>           3528</b>|N/A             (<span style="color:#555">*********</span>)</code></pre>
<p>Everything between the headline and the <code>- end of stdout/stderr</code> line is output
from your benchmark. The <code>- end of stdout/stderr</code> line changes depending on the
options you have given. For example in the <code>--nocapture=stdout</code> case this line
indicates your chosen option with <code>- end of stdout</code>.</p>
<p>Note that independently of the value of the <code>--nocapture</code> option, all logging
output of a valgrind tool itself is stored in files in the output directory of
the benchmark. Since Iai-Callgrind needs the logging output of valgrind tools
stored in files, there is no option to disable the creation of these log files.
But, if anything goes sideways you might be glad to have the log files around.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changing-the-color-output"><a class="header" href="#changing-the-color-output">Changing the color output</a></h1>
<p>The terminal output is colored per default but follows the value for the
<code>IAI_CALLGRIND_COLOR</code> environment variable. If <code>IAI_CALLGRIND_COLOR</code> is not set,
<code>CARGO_TERM_COLOR</code> is also tried. Accepted values are:</p>
<p><code>always</code>, <code>never</code>, <code>auto</code> (default).</p>
<p>So, disabling colors can be achieved with setting <code>IAI_CALLGRIND_COLOR</code> or
<code>CARGO_TERM_COLOR=never</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changing-the-logging-output"><a class="header" href="#changing-the-logging-output">Changing the logging output</a></h1>
<p>Iai-Callgrind uses <a href="https://crates.io/crates/env_logger">env_logger</a> and the
default logging level <code>WARN</code>. To set the logging level to something different,
set the environment variable <code>IAI_CALLGRIND_LOG</code> for example to
<code>IAI_CALLGRIND_LOG=DEBUG</code>. Accepted values are:</p>
<p><code>error</code>, <code>warn</code> (default), <code>info</code>, <code>debug</code>, <code>trace</code>.</p>
<p>The logging output is colored per default but follows the <a href="cli_and_env/output/./color.html">Color
settings</a>.</p>
<p>See also the <a href="https://docs.rs/env_logger/latest">documentation</a> of <code>env_logger</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="im-getting-the-error-sentinel--not-found"><a class="header" href="#im-getting-the-error-sentinel--not-found">I'm getting the error Sentinel ... not found</a></h1>
<p>You've most likely disabled creating debug symbols in your cargo <code>bench</code>
profile. This can originate in an option you've added to the <code>release</code> profile
since the <code>bench</code> profile inherits the <code>release</code> profile. For example, if you've
added <code>strip = true</code> to your <code>release</code> profile which is perfectly fine, you need
to disable this option in your <code>bench</code> profile to be able to run Iai-Callgrind
benchmarks.</p>
<p>See also the <a href="troubleshooting/../installation/prerequisites.html#debug-symbols">Debug Symbols</a>
section in Installation/Prerequisites.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-cargo-bench-results-in-an-unrecognized-option-error"><a class="header" href="#running-cargo-bench-results-in-an-unrecognized-option-error">Running cargo bench results in an "Unrecognized Option" error</a></h1>
<p>For</p>
<pre><code class="language-shell">cargo bench -- --some-valid-arg
</code></pre>
<p>to work you can either specify the
benchmark with <code>--bench BENCHMARK</code>, for example</p>
<pre><code class="language-shell">cargo bench --bench my_iai_benchmark -- --callgrind-args="--collect-bus=yes"
</code></pre>
<p>or add the following to your <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[lib]
bench = false
</code></pre>
<p>and if you have binaries</p>
<pre><code class="language-toml">[[bin]]
name = "my-binary"
path = "src/bin/my-binary.rs"
bench = false
</code></pre>
<p>Setting <code>bench = false</code> disables the creation of the implicit default <code>libtest</code>
harness which is added even if you haven't used <code>#[bench]</code> functions in your
library or binary. Naturally, the default harness doesn't know of the
Iai-Callgrind arguments and aborts execution printing the <code>Unrecognized Option</code> error.</p>
<p>If you cannot or don't want to add <code>bench = false</code> to your <code>Cargo.toml</code>, you can
alternatively use environment variables. For every <a href="troubleshooting/../cli_and_env/basics.html">command-line
argument</a> exists a corresponding environment variable.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comparison-of-iai-callgrind-with-criterion-rs"><a class="header" href="#comparison-of-iai-callgrind-with-criterion-rs">Comparison of Iai-Callgrind with Criterion-rs</a></h1>
<p>This is a comparison with
<a href="https://github.com/bheisler/criterion.rs?tab=readme-ov-file">Criterion-rs</a> but
some of the points in Pros and Cons also apply to other wall-clock time based
benchmarking frameworks.</p>
<p>Iai-Callgrind Pros:</p>
<ul>
<li>
<p>Iai-Callgrind can give answers that are repeatable to 7 or more significant
digits. In comparison, actual (wall-clock) run times are scarcely repeatable
beyond one significant digit.</p>
<p>This allows to implement and measure "microoptimizations". Typical
microoptimizations reduce the number of CPU cycles by <code>0.1%</code> or <code>0.05%</code> or
even less. Such improvements are impossible to measure with real-world
timings. But hundreds or thousands of microoptimizations add up, resulting in
measurable real-world performance gains.<sup class="footnote-reference"><a href="#note">1</a></sup></p>
</li>
<li>
<p>Iai-Callgrind can work reliably in noisy environments especially in CI
environments from providers like GitHub Actions or Travis-CI, where
Criterion-rs cannot.</p>
</li>
<li>
<p>The benchmark api of Iai-Callgrind is simple, intuitive and allows for a much
more concise and clearer structure of benchmarks.</p>
</li>
<li>
<p>Iai-Callgrind can benchmark functions in binary crates.</p>
</li>
<li>
<p>Iai-Callgrind can benchmark private functions.</p>
</li>
<li>
<p>Although Callgrind adds runtime overhead, running each benchmark exactly once
is still usually much faster than Criterion-rs' statistical measurements.</p>
</li>
<li>
<p>Criterion-rs creates plots and graphs about the averages, median etc. which
adds considerable execution time to the execution time for each benchmark.
Iai-Callgrind doesn't need any of these plots, since it can collect all its
metrics in a single run.</p>
</li>
<li>
<p>Iai-Callgrind generates profile output from the benchmark without further
effort.</p>
</li>
<li>
<p>With Iai-Callgrind you have native access to all the possibilities of all
Valgrind tools, including Valgrind Client Requests.</p>
</li>
</ul>
<p>Iai-Callgrind/Criterion-rs Mixed:</p>
<ul>
<li>Although it is usually not significant, due to the high precision of the
Iai-Callgrind measurements changes in the benchmarks themselves like adding a<br />
benchmark case can have an effect on the other benchmarks. Iai-Callgrind can
only try to reduce these effects to a minimum but never completely eliminate
them. Criterion-rs does not have this problem because it cannot detect such
small changes.</li>
</ul>
<p>Iai-Callgrind Cons:</p>
<ul>
<li>Iai-Callgrind's measurements merely correlate with wall-clock time. Wall-clock
time is an obvious choice in many cases because it corresponds to what users
perceive and Criterion-rs measures it directly.</li>
<li>Iai-Callgrind can only be used on platforms supported by Valgrind. Notably,
this does not include Windows.</li>
<li>Iai-Callgrind needs additional binaries, <code>valgrind</code> and the
<code>iai-callgrind-runner</code>. The version of the runner needs to be in sync with the
<code>iai-callgrind</code> library. Criterion-rs is only a library and the installation
is usually simpler.</li>
</ul>
<p>Especially, due to the first point in the <code>Cons</code>, I think it is still required
to run wall-clock time benchmarks and use <code>Criterion-rs</code> in conjunction with
Iai-Callgrind. But in the CI and for performance regression checks, you
shouldn't use <code>Criterion-rs</code> or other wall-clock time based benchmarks at all.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p><a href="https://sqlite.org/cpu.html#performance_measurement">https://sqlite.org/cpu.html#performance_measurement</a></p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comparison-of-iai-callgrind-with-iai"><a class="header" href="#comparison-of-iai-callgrind-with-iai">Comparison of Iai-Callgrind with Iai</a></h1>
<p>This is a comparison with <a href="https://github.com/bheisler/iai">Iai</a>, from which
Iai-Callgrind is forked over a year ago.</p>
<p>Iai-Callgrind Pros:</p>
<ul>
<li>
<p>Iai-Callgrind is actively maintained.</p>
</li>
<li>
<p>The benchmark api of Iai-Callgrind is simple, intuitive and allows for a much
more concise and clearer structure of benchmarks.</p>
</li>
<li>
<p>More stable metrics because the benchmark function is virtually encapsulated
by Callgrind and separates the benchmarked code from the surrounding code.</p>
</li>
<li>
<p>Iai-Callgrind excludes setup code from the metrics natively.</p>
</li>
<li>
<p>The Callgrind output files are much more focused on the benchmark function and
the function under test than the Cachegrind output files that Iai produces.
The calibration run of Iai only sanitized the visible summary output but not
the metrics in the output files themselves. So, the output of <code>cg_annotate</code>
was still cluttered by the initialization code, setup functions and metrics.</p>
</li>
<li>
<p>Changes to the library of Iai-Callgrind have almost never an influence on the
benchmark metrics, since the actual runner (<code>iai-callgrind-runner</code>) and thus
<code>99%</code> of the code needed to run the benchmarks is isolated from the
benchmarks by an independent binary. In contrast to the library of Iai which
is compiled together with the benchmarks.</p>
</li>
<li>
<p>Iai-Callgrind has functionality in place that provides a more constant
environment, like the <code>Sandbox</code> and clearing environment variables.</p>
</li>
<li>
<p>Supports running other Valgrind Tools, like DHAT, Massif etc.</p>
</li>
<li>
<p>Comparison of benchmark functions.</p>
</li>
<li>
<p>Iai-Callgrind can be configured to check for performance regressions.</p>
</li>
<li>
<p>A complete implementation of Valgrind Client Requests is available in
Iai-Callgrind itself.</p>
</li>
<li>
<p>Comparison of benchmarks to baselines instead of only to <code>.old</code> files.</p>
</li>
<li>
<p>Iai-Callgrind natively supports benchmarking binaries.</p>
</li>
<li>
<p>Iai-Callgrind can print machine-readable output in <code>.json</code> format.</p>
</li>
</ul>
<p>I don't see any downside in using Iai-Callgrind instead of Iai.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="js/dropdown.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
